{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math, random\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCTS is equivalent Monte Carlo control with UCB applied to the sub-MDP starting from the current state, where table lookup is represented by a tree. Since the action leads to deterministic results, $q(s,a)=v(s'_{\\rm a})$. $\\gamma=1$ and r=0 until endgame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barebone MCTS with UCT\n",
    "https://youtu.be/ItMutbeOHtc?t=3922, https://www.youtube.com/watch?v=Bm7zah_LrmE\n",
    "\n",
    "1. From each node (a node = a state of the board), repeat trying unexplored moves and rollout randomly unil gameover. The win/lose count is propagated back along the path (only above or at the level where new moves are being tried out -- for memory constraints) taken for each node\n",
    "2. when all moves of the node have been tried at least once, *select* the one to try based on **Upper Confidence Bound** UCB (mean value + C\\*uncertainty of the mean $\\propto\\sqrt{\\frac{\\log N_{\\rm visit}}{n_{\\rm child's visit}}}$). Repeat doing this until there is at least an untried move at the node\n",
    "3. repeat 1&2 until desired time/iteration limit, then select the best move at root node (current real situation of the board) based on *mean value* of each move\n",
    "\n",
    "4. consider some nodes may be reached from different ways; so keep the {move: child_node} dictionary. when selecting child node, return the corresponding move and child_node also (do not use parent of a node to backtrack)\n",
    "5. ONLY for terminating (acyclic) games\n",
    "6. Keep the nodes that (in principle) could be reached from the current state in the future. Game class need to implement `Reachable` wrt its key for this to work. Otherwise keep every node (memory...)\n",
    "7. prune tree from the leaf. If searched to the end game already, we know the value of node exactly at that point, and can know if previous state will definitely (not) move towards there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: [mcts.ai](http://mcts.ai/code/python.html) recursive + node reuse + pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instance of game class is passed to `MCTS`'s `search` function, and must have:\n",
    "* `playerToMove`: 1 or 2\n",
    "* `GetMoves()`: returns list of (hashable) valid moves from current state\n",
    "* `Move(m)`: execute the passed in move (which is guaranteed to be chosen from `GetMoves()`)\n",
    "* `RollOut()`: randomly execuate the game until game over\n",
    "* `GetResult(viewpoint)`: (after game over) returns the reward (1 or 0) from the specified viewpoint (1 or 2 -- corresponding to playerToMove)\n",
    "* `key()`: returns a string fully and uniquely characterize the status of the game\n",
    "* [Optional]`Reachable(k)`: returns whether (True/False) the game could in principle reach the state represented by the passed-in key `k`, which was generated by the `key()` function of another state. If not provided, prune tree by deleting nodes not visited during a search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     117
    ]
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\" Wins is always from the viewpoint of player Just Moved.\"\"\"\n",
    "    def __init__(self, state = None):\n",
    "        self.childNodes = {} # {move:nextnode} the move that get *into* next node\n",
    "        self.viewpoint = 3-state.playerToMove\n",
    "        self.wins = 0  #for the player Just Moved\n",
    "        self.visits = 0\n",
    "        self.untriedMoves = state.GetMoves() # future child nodes\n",
    "        \n",
    "    def UCTSelectChild(self,explore=1):\n",
    "        \"\"\" Use the UCB1 formula to select a child node. Often a constant UCTK is applied so we have\n",
    "            lambda c: c.wins/c.visits + UCTK * sqrt(2*log(self.visits)/c.visits to vary the amount of\n",
    "            exploration versus exploitation. \n",
    "        \"\"\"\n",
    "        return max(list(self.childNodes.items()), \n",
    "                   key = lambda c: c[1].wins/c[1].visits + explore*math.sqrt(math.log(self.visits)/c[1].visits) )\n",
    "    \n",
    "    def AddChild(self, move, s, n):\n",
    "        \"\"\" Remove m from untriedMoves and add a new child node for this move. if provided, use that  \"\"\"\n",
    "        self.untriedMoves.remove(move)\n",
    "        self.childNodes[move] = n\n",
    "        return n\n",
    "    \n",
    "    def Update(self, result, visits=None):\n",
    "        \"\"\" update visit & win counts. (from the viewpoint of player Just Moved) \"\"\"\n",
    "        self.visits += 1\n",
    "        self.wins += result # game results in the range [0.0, 1.0]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[W/V: {self.wins:6g}/{self.visits:6d} | UnXplrd: {len(self.untriedMoves)}] \"\n",
    "\n",
    "    def TreeToString(self, indent):\n",
    "        s = \"\\n\"+ \"| \"*indent + str(self)\n",
    "        s += ''.join(c.TreeToString(indent+1)+str(m) for m,c in self.childNodes.items())\n",
    "        return s\n",
    "\n",
    "    def ChildrenToString(self):        \n",
    "        return \"\\n\".join(f'{str(m):8s}|{c}' for m,c in sorted(self.childNodes.items(),key=lambda e: e[1].wins/e[1].visits))\n",
    "    \n",
    "class MCTS():   #reuses nodes\n",
    "    def __init__(self, game):\n",
    "        self.nodes = {}               #store all nodes previously explored\n",
    "        self.game = game\n",
    "        self.inf = float('inf')\n",
    "\n",
    "    def search(self, timemax=None, itermax=None, explore=1, verbose=0):\n",
    "        key=self.game.key()\n",
    "        if 'Reachable' in dir(self.game): #pruning by (game provided) finding which node will be reachable\n",
    "            self.nodes = {k:v for k,v in self.nodes.items() if k==key or self.game.Reachable(k)}\n",
    "\n",
    "        if self.rootnode.untriedMoves or len(self.rootnode.childNodes)>1:  #unimportant -- determine when to stop\n",
    "            if itermax or timemax:\n",
    "                start=time.time()\n",
    "                i = 0\n",
    "                while (timemax is None or time.time()<start+timemax) and\\\n",
    "                      (itermax is None or i<itermax):\n",
    "                    i = i+100\n",
    "                    for _ in range(100):\n",
    "                        v=self.simulate(deepcopy(self.game),self.rootnode)\n",
    "                    if abs(v)==self.inf: break\n",
    "            else: #debug\n",
    "                start=time.time()\n",
    "                while True:\n",
    "                    for _ in range(1000): v=self.simulate(deepcopy(self.game),self.rootnode)\n",
    "                    print(time.time()-start,sum(c.visits for c in self.rootnode.childNodes.values()),\n",
    "                          sorted(list(self.rootnode.childNodes.items()), \n",
    "                              key = lambda c: -c[1].wins/c[1].visits ),\n",
    "                          end='\\r')\n",
    "                    if abs(v)==self.inf: break\n",
    "                    \n",
    "        moveToChild, bestChild = self.rootnode.UCTSelectChild(explore=0)\n",
    "        if verbose==2:   print(self.rootnode.TreeToString(0))\n",
    "        elif verbose==1: print(self.rootnode.ChildrenToString())\n",
    "            \n",
    "        return moveToChild    \n",
    "    \n",
    "    @property  #  called when accessing self.rootnode\n",
    "    def rootnode(self):\n",
    "        key = self.game.key()\n",
    "        if key not in self.nodes:\n",
    "            self.nodes[key] = Node(state = self.game)\n",
    "        return self.nodes[key]\n",
    "    \n",
    "    def simulate(self,state,node,explore=1):\n",
    "        if node.untriedMoves == [] and node.childNodes != {}: #fully expanded, non-terminal\n",
    "            move,nnode = node.UCTSelectChild(explore) #descend (following UCB) \n",
    "            if nnode.wins==self.inf or nnode.wins==-self.inf: #if the best is -inf or inf already, can backprop\n",
    "                node.Update(-nnode.wins)\n",
    "                return -nnode.wins\n",
    "            state.Move(move)\n",
    "            v = self.simulate(state,nnode)\n",
    "            if v==-self.inf: v=0 # if v==-inf, next mover will not choose this branch as it leads to loss.\n",
    "                            # Note: other branch may have finite v as UCT  saw this branch as finite v before simulation\n",
    "            node.Update(1-v)\n",
    "            return 1-v\n",
    "        elif node.untriedMoves != []: #not fully expanded: expand and then rollout\n",
    "            move = random.choice(node.untriedMoves) \n",
    "            state.Move(move)\n",
    "            k = state.key()\n",
    "            if k in self.nodes:\n",
    "                nnode = self.nodes[k]\n",
    "            else:\n",
    "                nnode = Node(state = state)\n",
    "                self.nodes[k] = nnode\n",
    "            node.AddChild(move,state,nnode)\n",
    "            state.RollOut()\n",
    "            v = state.GetResult(nnode.viewpoint) #not setting inf or -inf because there are indeterminism (unexplored moves)\n",
    "            nnode.Update(v)\n",
    "            node.Update(1-v)\n",
    "            return 1-v\n",
    "        elif node.childNodes == {}: #terminal\n",
    "            v = state.GetResult(node.viewpoint)\n",
    "            if v==1:    v=self.inf\n",
    "            elif v==0:  v=-self.inf\n",
    "            node.Update(v)\n",
    "            return v\n",
    "    \n",
    "    def __simulate(self,state,node): #old, iterative version\n",
    "        path = [node]\n",
    "        #descend (following UCB) to the first branch not fully expanded (some moves not tried), or reaching end of game\n",
    "        while node.untriedMoves == [] and node.childNodes != {}:\n",
    "            move,node = node.UCTSelectChild(self.explore)\n",
    "            if node.wins==float('inf') or node.wins==float('-inf'): #if the best is -inf or inf, can backprop already\n",
    "                path[-1].Update(-node.wins)\n",
    "                return\n",
    "            state.Move(move)\n",
    "            path += node,\n",
    "        \n",
    "        # if there are unexplored expand (add a childNode) and move the state into it \n",
    "        if node.untriedMoves != []: \n",
    "            move = random.choice(node.untriedMoves) \n",
    "            state.Move(move)\n",
    "            k = state.key()\n",
    "            if k in self.nodes:\n",
    "                nextnode = self.nodes[k]\n",
    "            else:\n",
    "                nextnode = Node(state = state)\n",
    "                \n",
    "            node.AddChild(move,state,nextnode)\n",
    "            self.nodes[k] = nextnode\n",
    "            node = nextnode\n",
    "            path += node,\n",
    "        elif node.childNodes == {}: #nothing unexplored and is terminal: delete this child for its parent if loss\n",
    "            reward = state.GetResult(node.viewpoint)\n",
    "            if reward==1:\n",
    "                node.Update(float('inf'))\n",
    "            elif reward==0:\n",
    "                node.Update(float('-inf'))\n",
    "\n",
    "        # Rollout to END of a game randomly (not expanding childNodes -- just want to estimate the newly added node's value)\n",
    "        state.RollOut()\n",
    "\n",
    "        # state is now terminal; backpropagate this game's result to its path's nodes' win counts\n",
    "        reward = state.GetResult(node.viewpoint)\n",
    "        for n in path:\n",
    "            if n.viewpoint == node.viewpoint:\n",
    "                n.Update(reward)\n",
    "            else:\n",
    "                n.Update(1-reward)\n",
    "        if self.prune: self.visitedNode|=set(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [m,n,k-game](https://en.wikipedia.org/wiki/M,n,k-game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#contains current state and who has last moved\n",
    "import itertools\n",
    "class OXO:\n",
    "    def __init__(self,width=3,height=3,inarow=None,moves_per_round=None,end1=True): # game ends as one success\n",
    "        self.playerToMove = 1\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.board = [0]*width*height # 0 = empty, 1 = player 1, 2 = player 2\n",
    "        self.empty = list(range(width*height))\n",
    "        self.moves_per_round = moves_per_round or 1\n",
    "        self.end1 = end1\n",
    "        \n",
    "        # winning linesrequires\n",
    "        inarow = inarow or min(width,height)\n",
    "        self.lines = [tuple(range(i*width+j,i*width+j+inarow)) for i in range(0,height) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,(i+inarow)*width+j,width)) for i in range(0,height-inarow+1) for j in range(width)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width+1),width+1)) for i in range(height-inarow+1) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width-1),width-1)) for i in range(height-inarow+1) for j in range(inarow-1,width)]\n",
    "\n",
    "    def Move(self, move):\n",
    "        \"\"\" Update a state by carrying out the given move. Must also update playerToMove.  \"\"\"\n",
    "        for m in move:\n",
    "            self.board[m] = self.playerToMove\n",
    "            self.empty.remove(m)\n",
    "        if self.end1 and self.GetResult(self.playerToMove) in [0,1]:  \n",
    "            self.empty=[]\n",
    "        self.playerToMove = 3 - self.playerToMove\n",
    "        \n",
    "    def GetMoves(self): # must clone as Node use this return as untriedMoves  # return self.empty[:]\n",
    "        return list(itertools.combinations(self.empty,self.moves_per_round))\n",
    "    \n",
    "    def RollOut(self):\n",
    "        possibleMoves = self.GetMoves()\n",
    "        while possibleMoves:\n",
    "            self.Move(random.choice(possibleMoves))\n",
    "            possibleMoves = self.GetMoves()\n",
    "    \n",
    "    def GetResult(self, viewpoint):  # reward from `viewpoint`, in the range [0.0, 1.0]\n",
    "        myscore = opposcore = 0\n",
    "        for l in self.lines:\n",
    "            one=self.board[l[-1]]\n",
    "            if one!=0 and all(self.board[p]==one for p in l):\n",
    "                if one == viewpoint:\n",
    "                    myscore += 1\n",
    "                else:\n",
    "                    opposcore += 1\n",
    "        if myscore>opposcore: return 1\n",
    "        elif opposcore>myscore: return 0\n",
    "        return 0.5\n",
    "\n",
    "    def __repr__(self): # for output: 1 (X), 2 = (O)\n",
    "        lines=[''.join(\"·XO\"[self.board[i*self.width+j]] for j in range(self.width)) for i in range(self.height)]\n",
    "        return '\\n'.join(lines)    \n",
    "    def key(self): #string containing all information for hashing the node\n",
    "        return str(self.playerToMove)+''.join(\"·XO\"[e] for e in self.board)\n",
    "    def Reachable(self,key):  #for pruning Tree\n",
    "        mykey = self.key()\n",
    "        return all(ch in '·12' or ch==key[i] for i,ch in enumerate(mykey))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fail to draw on 5,5,4, 2nd: after first player places at center, 2nd player should play at a position \"diagonal\" to the center (6,8,16,18). MCTS failed to identify these four as optimal until after ~10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.54305410385132 187057 [((7,), [W/V:   -inf/  1963 | UnXplrd: 0] ), ((17,), [W/V:   -inf/  1776 | UnXplrd: 0] ), ((24,), [W/V:   -inf/  1200 | UnXplrd: 0] ), ((22,), [W/V:   -inf/  1252 | UnXplrd: 0] ), ((15,), [W/V:   -inf/  1937 | UnXplrd: 0] ), ((21,), [W/V:   -inf/  1022 | UnXplrd: 0] ), ((8,), [W/V:   -inf/ 40407 | UnXplrd: 0] ), ((0,), [W/V:   -inf/  1276 | UnXplrd: 0] ), ((20,), [W/V:   -inf/ 58231 | UnXplrd: 0] ), ((2,), [W/V:   -inf/  1140 | UnXplrd: 0] ), ((4,), [W/V:   -inf/ 59477 | UnXplrd: 0] ), ((18,), [W/V:   -inf/  1598 | UnXplrd: 0] ), ((5,), [W/V:   -inf/  1931 | UnXplrd: 0] ), ((23,), [W/V:   -inf/  2030 | UnXplrd: 0] ), ((3,), [W/V:   -inf/  2178 | UnXplrd: 0] ), ((13,), [W/V:   -inf/  1510 | UnXplrd: 0] ), ((19,), [W/V:   -inf/  1616 | UnXplrd: 0] ), ((1,), [W/V:   -inf/  1324 | UnXplrd: 0] ), ((10,), [W/V:   -inf/  1018 | UnXplrd: 0] ), ((14,), [W/V:   -inf/  1275 | UnXplrd: 0] ), ((9,), [W/V:   -inf/  1623 | UnXplrd: 0] ), ((6,), [W/V:   -inf/  1273 | UnXplrd: 0] )]]]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts = MCTS(OXO(width=5,height=5,inarow=4))\n",
    "mcts.game.Move((12,)) # after this, found (6/8/16/18) is optimal after ~1,500,000 simulations\n",
    "mcts.game.Move((11,)) # after this, found sure win policy after 260663 simulations\n",
    "mcts.game.Move((16,)) # after this, found sure loss after 189564 simulations\n",
    "# mcts.game.Move((8,))  # after this, found sure win policy after 38150 simulations\n",
    "# mcts.game.Move((18,)) # after this, found sure loss after 25918 simulations\n",
    "# mcts.game.Move((6,))  # after this, found sure win policy after 1601 simulations\n",
    "mcts.search(timemax=None,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "game = OXO(width=3,height=3,inarow=3,moves_per_round=1,end1=True) #traditional\n",
    "# game = OXO(width=5,height=5,inarow=4) #http://boulter.com/ttt/\n",
    "# game = OXO(width=8,height=8,inarow=4,moves_per_round=2,end1=False) #http://www.atksolutions.com/games/tictactoedeluxe.html\n",
    "# game = OXO(width=15,height=15,inarow=5) #Gomoku\n",
    "mcts = MCTS(game)\n",
    "while mcts.game.GetMoves():\n",
    "    if mcts.game.playerToMove==0:\n",
    "#         clear_output()\n",
    "        board=np.array([f'{(\"·XO\"[s] if s else str(pos)):2s}' for pos,s in enumerate(mcts.game.board)]).reshape(mcts.game.height,mcts.game.width)\n",
    "        print(board)\n",
    "        n=mcts.rootnode\n",
    "        print(n.ChildrenToString())\n",
    "        print(f'choose from: {mcts.game.GetMoves()[:10]}...',end='')\n",
    "        m = (int(input()),)   #2 moves (int(input()),int(input()))\n",
    "    else:\n",
    "        m = mcts.search(timemax=1,verbose=1)\n",
    "    mcts.game.Move(m)\n",
    "    print(mcts.game)\n",
    "    print(len(mcts.nodes))\n",
    "if mcts.game.GetResult(1) == 1:   print(\"Player 1(X) wins!\")\n",
    "elif mcts.game.GetResult(2) == 1: print(\"Player 2(O) wins!\")\n",
    "else: print(\"Nobody wins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ConnectN:\n",
    "    def __init__(self,width=7,height=6,inarow=4):\n",
    "        self.playerToMove = 1\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.board = [0]*width*height\n",
    "        self.moves = list(range(width))\n",
    "        self.firstEmpty = [height-1]*width\n",
    "        \n",
    "        # winning lines\n",
    "        inarow = inarow or min(width,height)\n",
    "        self.lines = [tuple(range(i*width+j,i*width+j+inarow)) for i in range(0,height) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,(i+inarow)*width+j,width)) for i in range(0,height-inarow+1) for j in range(width)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width+1),width+1)) for i in range(height-inarow+1) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width-1),width-1)) for i in range(height-inarow+1) for j in range(inarow-1,width)]\n",
    "\n",
    "    def Move(self, move):  #move=column idx\n",
    "        assert move in self.moves\n",
    "        self.board[self.firstEmpty[move]*self.width+move]=self.playerToMove\n",
    "        self.firstEmpty[move] -= 1\n",
    "        if self.firstEmpty[move]<0:\n",
    "            self.moves.remove(move)\n",
    "        if self.GetResult(self.playerToMove) in [0,1]:  #indicate game ended as someone won\n",
    "            self.moves=[] \n",
    "        self.playerToMove = 3 - self.playerToMove\n",
    "        \n",
    "    def GetMoves(self):  # legal moves for next player. empty if game is over\n",
    "        return self.moves[:]\n",
    "    \n",
    "    def RollOut(self):\n",
    "        while self.moves:\n",
    "            self.Move(random.choice(self.moves))\n",
    "    \n",
    "    def GetResult(self, viewpoint):  # reward from `viewpoint`, in the range [0.0, 1.0]\n",
    "        for l in self.lines:\n",
    "            one=self.board[l[-1]]\n",
    "            if one!=0 and all(self.board[p]==one for p in l):\n",
    "                if one == viewpoint:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "        return 0.5\n",
    "\n",
    "    def __repr__(self): # string representation: 1 (X), 2 = (O)\n",
    "        s = ''\n",
    "        for left in range(0,self.width*self.height,self.width):\n",
    "            for sh in range(self.width):\n",
    "                s+=\"·XO\"[self.board[left+sh]]\n",
    "            s+='\\n'\n",
    "        return s.strip()\n",
    "    def key(self): #string containing all information for hashing the node\n",
    "        return str(self.playerToMove)+''.join(\"·XO\"[e] for e in self.board)\n",
    "    def Reachable(self,key):  #for pruning Tree\n",
    "        mykey = self.key()\n",
    "        return all(ch in '12·' or ch==key[i] for i,ch in enumerate(mykey)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fails to deduce that the 5th move (1st player) should be at center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "game = ConnectN(7,6,4) #https://connect4.gamesolver.org/\n",
    "for _ in range(4): game.Move(3)\n",
    "mcts = MCTS(game)\n",
    "while mcts.game.GetMoves():\n",
    "    if mcts.game.playerToMove==2:\n",
    "#         clear_output()\n",
    "        fn = lambda s: s if int(s)<7 else ''\n",
    "        board=np.array([f'{(\"·XO\"[s] if s else fn(str(pos))):2s}' for pos,s in enumerate(mcts.game.board)])\n",
    "        print(board.reshape(mcts.game.height,mcts.game.width))\n",
    "        print(mcts.rootnode.ChildrenToString())\n",
    "        print('choose from:',end='')\n",
    "        m = int(input(mcts.game.GetMoves()))\n",
    "    else:\n",
    "        m = mcts.search(timemax=10,verbose=1,explore=2)\n",
    "    mcts.game.Move(m)\n",
    "    print(mcts.game)\n",
    "    print(len(mcts.nodes))\n",
    "if mcts.game.GetResult(1) == 1:   print(\"Player 1(X) wins!\")\n",
    "elif mcts.game.GetResult(2) == 1: print(\"Player 2(O) wins!\")\n",
    "else: print(\"Nobody wins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Othello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Othello:\n",
    "    def __init__(self, size = 8):  # size must be integral and even\n",
    "        self.playerToMove = 1\n",
    "        self.size = size\n",
    "        self.board = [] # 0 = empty, 1 = player 1, 2 = player 2\n",
    "        for y in range(self.size):\n",
    "            self.board.append([0]*size)\n",
    "        self.board[size//2][size//2] = self.board[size//2-1][size//2-1] = 2\n",
    "        self.board[size//2][size//2-1] = self.board[size//2-1][size//2] = 1\n",
    "        self.board = [e for l in self.board for e in l]\n",
    "\n",
    "    def Move(self, move):\n",
    "        if move is not None:\n",
    "            (x,y)=divmod(move,self.size)\n",
    "            assert self.IsOnBoard(x,y) and self.board[x*self.size+y] == 0\n",
    "            m = self.GetAllSandwichedCounters(x,y)\n",
    "            self.board[x*self.size+y] = self.playerToMove\n",
    "            for (a,b) in m:\n",
    "                self.board[a*self.size+b] = self.playerToMove\n",
    "        self.playerToMove = 3 - self.playerToMove\n",
    "    \n",
    "    def GetMoves(self):\n",
    "        emptypos = [pos for pos,e in enumerate(self.board) if e==0]\n",
    "        if not emptypos:\n",
    "            return []\n",
    "        else:\n",
    "            viable = [pos for pos in emptypos if self.ExistsSandwiched(*divmod(pos,self.size))] \n",
    "            if viable:\n",
    "                return viable\n",
    "            else:  #need to check if opponent also has no viable pos\n",
    "                self.playerToMove = 3 - self.playerToMove\n",
    "                oppoViable = [pos for pos in emptypos if self.ExistsSandwiched(*divmod(pos,self.size))]\n",
    "                self.playerToMove = 3 - self.playerToMove\n",
    "                if oppoViable:\n",
    "                    return [None]\n",
    "                else:\n",
    "                    return []\n",
    "    \n",
    "    def RollOut(self):\n",
    "        emptypos = [pos for pos,e in enumerate(self.board) if e==0]\n",
    "        bad=0 \n",
    "        while emptypos:\n",
    "            random.shuffle(emptypos)\n",
    "            for pos in emptypos:\n",
    "                if self.ExistsSandwiched(*divmod(pos,self.size)):\n",
    "                    self.Move(pos)\n",
    "                    emptypos = [i for i,e in enumerate(self.board) if e==0]\n",
    "                    break\n",
    "            else:\n",
    "                if bad<2: #when bad=2, both side cannot play, game ends\n",
    "                    bad+=1\n",
    "                    self.Move(None)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    def AdjacentEnemyDirections(self,x,y):# Speeds up GetMoves by only considering squares which are adjacent to an enemy-occupied square.\n",
    "        return [(dx,dy) for (dx,dy) in [(0,+1),(+1,+1),(+1,0),(+1,-1),(0,-1),(-1,-1),(-1,0),(-1,+1)]\n",
    "                        if self.IsOnBoard(x+dx,y+dy) and self.board[(x+dx)*self.size+y+dy] == 3-self.playerToMove]\n",
    "    \n",
    "    def ExistsSandwiched(self,x,y):# Is there at least one counter which would be flipped if my counter was placed at (x,y)? \n",
    "        for (dx,dy) in self.AdjacentEnemyDirections(x,y):\n",
    "            x1=x+dx\n",
    "            y1=y+dy\n",
    "            while self.IsOnBoard(x1,y1) and self.board[x1*self.size+y1] == 3 - self.playerToMove:\n",
    "                x1 += dx\n",
    "                y1 += dy\n",
    "            if self.IsOnBoard(x1,y1) and self.board[x1*self.size+y1] == self.playerToMove:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def GetAllSandwichedCounters(self, x, y):# Is (x,y) a possible move (i.e. opponent counters are sandwiched between (x,y) and my counter in some direction)?\n",
    "        sandwiched = []\n",
    "        for (dx,dy) in self.AdjacentEnemyDirections(x,y):\n",
    "            sandwiched.extend(self.SandwichedCounters(x,y,dx,dy))\n",
    "        return sandwiched\n",
    "\n",
    "    def SandwichedCounters(self, x, y, dx, dy):# Return the coordinates of all opponent counters sandwiched between (x,y) and my counter.\n",
    "        x += dx\n",
    "        y += dy\n",
    "        sandwiched = []\n",
    "        while self.IsOnBoard(x,y) and self.board[x*self.size+y] == 3 - self.playerToMove:\n",
    "            sandwiched.append((x,y))\n",
    "            x += dx\n",
    "            y += dy\n",
    "        if self.IsOnBoard(x,y) and self.board[x*self.size+y] == self.playerToMove:\n",
    "            return sandwiched\n",
    "        else:\n",
    "            return [] # nothing sandwiched\n",
    "\n",
    "    def IsOnBoard(self, x, y):\n",
    "        return x >= 0 and x < self.size and y >= 0 and y < self.size\n",
    "    \n",
    "    def GetResult(self, viewpoint): #after gameover\n",
    "        viewpointscore=oppositescore=0\n",
    "        for e in self.board:\n",
    "            if e==viewpoint: viewpointscore+=1\n",
    "            elif e==3-viewpoint: oppositescore+=1\n",
    "        if viewpointscore > oppositescore: return 1.0\n",
    "        elif oppositescore > viewpointscore: return 0.0\n",
    "        else: return 0.5 # draw\n",
    "\n",
    "    def __repr__(self):\n",
    "        s= \"\"\n",
    "        for x in range(self.size):\n",
    "            for y in range(self.size):\n",
    "                s += \"·XO\"[self.board[x*self.size+y]]\n",
    "            s += \"\\n\"\n",
    "        return s.strip()\n",
    "    def key(self): #string containing all information for hashing the node\n",
    "        return str(self.playerToMove)+''.join(\"·XO\"[e] for e in self.board)\n",
    "    def Reachable(self,key):  #for pruning Tree\n",
    "        mykey = self.key()\n",
    "        return key.count('·')<mykey.count('·') and \\\n",
    "               all(ch in '12·' or key[i]!='·' for i,ch in enumerate(mykey)) and\\\n",
    "               (mykey[1]=='·' or mykey[1]==key[1]) and\\\n",
    "               (mykey[self.size]=='·' or mykey[self.size]==key[self.size]) and\\\n",
    "               (mykey[-self.size]=='·' or mykey[-self.size]==key[-self.size]) and\\\n",
    "               (mykey[-1]=='·' or mykey[-1]==key[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* timemax=60 beats Reversu Difficult\n",
    "* timemax=15 beats Reversu Medium, lost to Reversu Difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "game = Othello(8)\n",
    "mcts = MCTS(game)\n",
    "while mcts.game.GetMoves():\n",
    "    if mcts.game.playerToMove==2:\n",
    "        clear_output()\n",
    "        board=np.array([f'{(\"·XO\"[e] if e else str(p)):2s}' for p,e in enumerate(mcts.game.board)]).reshape(8,8)\n",
    "        print(board)\n",
    "        print(mcts.rootnode.ChildrenToString())\n",
    "        print('choose from:',end='')\n",
    "        moves = mcts.game.GetMoves()\n",
    "        if moves[0] is None: m = None\n",
    "        else: m=int(input(moves))\n",
    "    else:\n",
    "        m = mcts.search(verbose=1,timemax=3+len(list(filter(None,mcts.game.board)))*0 )  #len...=number of pieces on board\n",
    "    mcts.game.Move(m)\n",
    "    print(mcts.game)\n",
    "    print(len(mcts.nodes))\n",
    "if mcts.game.GetResult(1) == 1:   print(\"Player 1(X) wins!\")\n",
    "elif mcts.game.GetResult(2) == 1: print(\"Player 2(O) wins!\")\n",
    "else: print(\"Nobody wins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero-style (guide tree search by policy+value network)\n",
    "\n",
    "https://www.youtube.com/watch?v=ld28AU7DDB4\n",
    "* The uncertainty term used in UCB is replaced by **Polynomial Upper Confidence Trees** PUCT $\\propto P(s_i|s)\\frac{\\sqrt{N}}{1+n_i}$ (where N is the total visits of current state s, and n_i are visit counts of each of the next possible nodes). $P(s_i|s)$ is a probability output by policy network given current state\n",
    "* Rollout replaced by the value estimation of the current state by the network. For a newly-expanded child node (c), use value network to compute all the values of its possible child nodes (c's c), used for computing the mean of the current (c) node, with weights given by the policy network.\n",
    "* In AlphaGo, policy network is trained with human expert positions. Then policy network is then used to play against itself to generate positions + target (win/loss) for training the value network\n",
    "* AlphaZero combines policy and value network into a single network. Repeat:\n",
    "  1. training examples (state,policy of next move,win/loss) are generated by MCTS, used to train the policy+value network.\n",
    "  2. Use the network trained to guide MCTS\n",
    "  \n",
    "Other tweaks\n",
    "* in the PUCT, normalize (sum of all=1) and *then* exponentiate all counts before putting into formula $N^{1/\\tau}$ and $n_i^{1/\\tau}$, where $\\tau=1$ for the first 10-100 moves (exploratory) and ~0 for later moves (only choose the best).\n",
    "* After each iteration, pit against previous version of the net to make sure it has really improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Code](http://web.stanford.edu/~surag/posts/alphazero.html) (modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Game` class requires:\n",
    "* `reset()` returns init board (numpy array passable to net)\n",
    "* `actionSize` the largest possible number of moves (not given a state). e.g. Othello is size^2-4+1 (for pass)\n",
    "* `getValidMoves()` returns np.array of 0/1 indicting the corresponding index action is a valid move or not at the moment\n",
    "* `board1`: Board in such a way that the one next move is always same set of numbers in the numpy array. e.g., for othello if playerToMove=2, return board*(-1). e.g. in chess if playerToMove=2, exchange pieces number 1-16 with number 17-32\n",
    "* `symConfig()`: input a policy (prob dist), generate tuples of (board**1**,policy) due to board symmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCTS given guidance from Net, generates (states,policies,values) through self-plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state = None):\n",
    "        self.childNodes = {} # {move:nextnode} the move that get *into* next node\n",
    "        self.policy = {}     # {move:prob}\n",
    "        self.viewpoint = 3-state.playerToMove\n",
    "        self.wins = 0        #for the player Just Moved = self.viewpoint\n",
    "        self.visits = 0\n",
    "        \n",
    "    def UCTSelectChild(self,explore=1):\n",
    "        mv = max(self.policy, \n",
    "                 key = lambda k: self.childNodes[k].wins/(self.childNodes[k].visits) + \\\n",
    "                       explore*self.policy[k]*math.sqrt(self.visits)/(1+self.childNodes[k].visits)\\\n",
    "                       if k in self.childNodes else explore*self.policy[k]*math.sqrt(self.visits+1e-8)\n",
    "                )\n",
    "        return mv\n",
    "    \n",
    "    def AddChild(self, move, s, n):\n",
    "        self.childNodes[move] = n\n",
    "        return n\n",
    "    \n",
    "    def Update(self, result):\n",
    "        self.visits += 1\n",
    "        self.wins += result # game results in the range [0.0, 1.0]\n",
    "    def __repr__(self):        return f\"[W/V: {self.wins:6g}/{self.visits:6d}] \"\n",
    "    def ChildrenToString(self):return \"\\n\".join(f'{str(m):8s}|{c}' for m,c in sorted(self.childNodes.items(),key=lambda e: e[1].wins/e[1].visits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "code_folding": [
     16
    ]
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "\n",
    "class MCTS():\n",
    "    def __init__(self, game, net):\n",
    "        self.game = game\n",
    "        self.net = net\n",
    "        self.numMCTSSims=25\n",
    "        self.inf = float('inf')\n",
    "        self.nodes = {}\n",
    "    def search(self, timemax=None, itermax=None, explore=1, verbose=False):\n",
    "        key=self.game.key()\n",
    "        if 'Reachable' in dir(self.game):\n",
    "            self.nodes = {k:v for k,v in self.nodes.items() if k==key or self.game.Reachable(k)}\n",
    "\n",
    "        if len(self.rootnode.policy)>1:  #unimportant -- determine when to stop\n",
    "            if itermax or timemax:\n",
    "                start=time.time()\n",
    "                i = 0\n",
    "                while (timemax is None or time.time()<start+timemax) and\\\n",
    "                      (itermax is None or i<itermax):\n",
    "                    i = i+100\n",
    "                    for _ in range(100):\n",
    "                        v=self.simulate(deepcopy(self.game),self.rootnode)\n",
    "                    if v==self.inf: break\n",
    "            else: #debug\n",
    "                start=time.time()\n",
    "                while True:\n",
    "                    for _ in range(1000): self.simulate(deepcopy(self.game),self.rootnode)\n",
    "                    print(time.time()-start,sum(c.visits for c in self.rootnode.childNodes.values()),\n",
    "                          sorted(list(self.rootnode.childNodes.items()), \n",
    "                              key = lambda c: -c[1].wins/c[1].visits ),\n",
    "                          end='\\r')\n",
    "                    \n",
    "        moveToChild = self.rootnode.UCTSelectChild(explore=0)\n",
    "        if verbose: print(self.rootnode.ChildrenToString())\n",
    "\n",
    "        return moveToChild    \n",
    "    \n",
    "    def net_predict(self,board1,valids): # returns a dict of {act:prob} for the valid moves, and a value of broad1's position\n",
    "        probs, v = self.net.predict(board1[np.newaxis])\n",
    "        probs = probs[0]*valids\n",
    "        sum_probs = np.sum(probs)\n",
    "        if sum_probs > 0:\n",
    "            probs /= sum_probs \n",
    "        else:# print(\"All valid moves were masked, do workaround.\")\n",
    "            probs = probs + valids\n",
    "            probs /= np.sum(probs)\n",
    "        return {a:probs[a] for a,val in enumerate(valids) if val}, v[0]\n",
    "    \n",
    "    def selfplay(self,temperature=lambda s: 1 if s<5 else 0): #train batch from one complete game\n",
    "        \"\"\"\n",
    "        This function executes one episode of self-play, starting with player 1.\n",
    "        As the game is played, each turn is added to trainExamples. After the game\n",
    "        ends, the outcome of the game is used to assign values to each example.\n",
    "        It uses a temp=1 if episodeStep < tempThreshold, and thereafter\n",
    "        uses temp=0.\n",
    "        Returns:\n",
    "            trainExamples: a list of examples of the form (canonicalBoard,pi,v)\n",
    "                           pi is the MCTS informed policy vector, v is +1 if\n",
    "                           the player eventually won the game, else -1.\n",
    "        \"\"\"\n",
    "        trainExamples = []\n",
    "        board = self.game.reset()\n",
    "\n",
    "        for movestep in count():\n",
    "            tau = temperature(movestep)\n",
    "\n",
    "            probs = self.getActionProb(tau)\n",
    "            \n",
    "            for board1,policy in self.game.symConfig(probs):\n",
    "                trainExamples += (self.game.playerToMove, board1.astype(np.float32), policy),  #value target not known yet\n",
    "\n",
    "            action = np.random.choice(len(probs), p=probs)\n",
    "            self.game.Move(action)\n",
    "\n",
    "            if not any(self.game.getValidMoves()):\n",
    "                r = self.game.GetResult(self.game.playerToMove)\n",
    "                return [(e[1],e[2],r if e[0]==self.game.playerToMove else 1-r) for e in trainExamples]\n",
    "        \n",
    "    @property  #  called when accessing self.rootnode\n",
    "    def rootnode(self):\n",
    "        key = self.game.key()\n",
    "        if key not in self.nodes:\n",
    "            self.nodes[key] = Node(state = self.game)\n",
    "            probs, v = self.net_predict(self.game.board1,self.game.getValidMoves())\n",
    "            self.nodes[key].policy = probs\n",
    "        return self.nodes[key]\n",
    "\n",
    "    def getActionProb(self, temp=1): #Returns: probs for next move by performing multiple searches starting from current state#\n",
    "        for _ in range(self.numMCTSSims):\n",
    "            self.simulate(deepcopy(self.game), self.rootnode)\n",
    "            \n",
    "        get_count=lambda c: 1e8 if c.wins==self.inf else 1e-8 if c.wins==-self.inf else c.visits #1e-8 to avoid all-zero\n",
    "        counts = [get_count(self.rootnode.childNodes[a]) if a in self.rootnode.childNodes else 0 for a in range(self.game.actionSize)]\n",
    "        if temp==0:\n",
    "            bestA = np.argmax(counts)\n",
    "            probs = [0]*len(counts)\n",
    "            probs[bestA]=1\n",
    "        else:\n",
    "            counts = [x**(1./temp) for x in counts]\n",
    "            probs = [x/float(sum(counts)) for x in counts]\n",
    "        return probs\n",
    "\n",
    "    def simulate(self, state, node, explore=1): #not aiming to fully expand every node\n",
    "        \"\"\"\n",
    "        At a newly expanded state, the net is called to return an initial P and v for the state.\n",
    "        If the leaf node is a terminal state, the value is v. the value is propogated up the search path\n",
    "        \"\"\"\n",
    "        if node.policy == {}: #terminal\n",
    "            v = state.GetResult(node.viewpoint)\n",
    "            if v==1:    v=self.inf\n",
    "            elif v==0:  v=-self.inf\n",
    "            node.Update(v)\n",
    "            return v\n",
    "        else:                 # non-terminal\n",
    "            move = node.UCTSelectChild(explore) #descend (following UCB)\n",
    "            state.Move(move)\n",
    "            if move in node.childNodes:\n",
    "                nnode = node.childNodes[move]\n",
    "                if nnode.wins==self.inf or nnode.wins==-self.inf: #if the best is -inf or inf already, can backprop\n",
    "                    node.Update(-nnode.wins)\n",
    "                    return -nnode.wins\n",
    "            else:\n",
    "                k = state.key()                \n",
    "                if k in self.nodes:\n",
    "                    nnode = self.nodes[k]\n",
    "                else:\n",
    "                    nnode = Node(state = state)\n",
    "                    valid = state.getValidMoves()\n",
    "                    if np.any(valid):\n",
    "                        probs, v = self.net_predict(state.board1,valid)\n",
    "                        nnode.policy = probs\n",
    "                    self.nodes[k] = nnode\n",
    "                node.AddChild(move,state,nnode)\n",
    "            \n",
    "            v = self.simulate(state,nnode)\n",
    "            if v==-self.inf: v=0 # if v==-inf, next mover will not choose this branch as it leads to loss.\n",
    "                                 # Note: other branch may have finite v as UCT  saw this branch as finite v before simulation\n",
    "#             nnode.Update(v)\n",
    "            node.Update(1-v)\n",
    "            return 1-v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train net with dataset (states,policies,values) given by the self-plays of MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "@tf.function\n",
    "def train_step(net, boardstates, policies_target, values_target, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        policies, values = net(boardstates, training=True)\n",
    "        loss_p = tf.losses.softmax_cross_entropy(policies_target, policies)\n",
    "        loss_v = tf.losses.mean_squared_error(values_target, values)\n",
    "        combined_loss = loss_p + loss_v\n",
    "\n",
    "    grad = tape.gradient(combined_loss, net.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grad, net.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training script with a **Game** class and a **net**\n",
    "from collections import deque\n",
    "train_set = deque(maxlen=200000)\n",
    "mcts = MCTS(Game(),net)\n",
    "optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "for _ in range(100):\n",
    "    train_set += mcts.selfplay()\n",
    "    for s,p,v in tf.data.Dataset.from_tensor_slices(zip(*train_set)).shuffle(1000).batch(64):\n",
    "        train_step(net, s,p,v, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCTS using trained Net: given state, generate next move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example running) through script with a **Game** class and a **net**\n",
    "game = OXO(5,5,4)\n",
    "mcts = MCTS(game,net)\n",
    "while np.any(mcts.game.getValidMoves()):\n",
    "    m = mcts.search(timemax=10,verbose=1)\n",
    "    mcts.game.Move(m)\n",
    "    print(mcts.game, len(mcts.nodes))\n",
    "if mcts.game.GetResult(1) == 1:   print(\"Player 1(X) wins!\")\n",
    "elif mcts.game.GetResult(2) == 1: print(\"Player 2(O) wins!\")\n",
    "else: print(\"Nobody wins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [m,n,k-game](https://en.wikipedia.org/wiki/M,n,k-game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class OXO:\n",
    "    def __init__(self,width=3,height=3,inarow=None,end1=True): # game ends as one success\n",
    "        self.playerToMove = 1\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.end1 = end1\n",
    "        self.actionSize = width*height\n",
    "        self.reset()        \n",
    "        inarow = inarow or min(width,height)\n",
    "        self.lines = [tuple(range(i*width+j,i*width+j+inarow)) for i in range(0,height) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,(i+inarow)*width+j,width)) for i in range(0,height-inarow+1) for j in range(width)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width+1),width+1)) for i in range(height-inarow+1) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width-1),width-1)) for i in range(height-inarow+1) for j in range(inarow-1,width)]\n",
    "    \n",
    "    @property\n",
    "    def board1(self):\n",
    "        return self.board.reshape(self.height,self.width) if self.playerToMove==1\\\n",
    "               else np.mod(3-self.board,3).reshape(self.height,self.width)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.playerToMove = 1\n",
    "        self.board = np.zeros(self.width*self.height,dtype=np.int32)\n",
    "        self.empty = list(range(self.width*self.height))\n",
    "        \n",
    "    def getValidMoves(self): \n",
    "        return np.clip(1-self.board,0,None) if self.empty else np.zeros(self.actionSize)\n",
    "\n",
    "    def symConfig(self,pi):\n",
    "        board1 = self.board1\n",
    "        pi=np.array(pi).reshape(self.height,self.width)\n",
    "        return [(board1,pi.flatten()),\n",
    "                (np.rot90(board1,1),np.rot90(pi,1).flatten()),\n",
    "                (np.rot90(board1,2),np.rot90(pi,2).flatten()),\n",
    "                (np.rot90(board1,3),np.rot90(pi,3).flatten()),\n",
    "                (np.flip(board1,0), np.flip(pi,0).flatten()),\n",
    "                (np.rot90(np.flip(board1,0),1), np.rot90(np.flip(pi,0),1).flatten()),\n",
    "                (np.rot90(np.flip(board1,0),2), np.rot90(np.flip(pi,0),2).flatten()),\n",
    "                (np.rot90(np.flip(board1,0),3), np.rot90(np.flip(pi,0),3).flatten()),\n",
    "               ]\n",
    "\n",
    "    def Move(self, move):\n",
    "        assert move in self.empty\n",
    "        self.board[move] = self.playerToMove\n",
    "        self.empty.remove(move)\n",
    "        if self.end1 and self.GetResult(self.playerToMove) in [0,1]:  \n",
    "            self.empty=[]\n",
    "        self.playerToMove = 3 - self.playerToMove\n",
    "\n",
    "    def GetResult(self, viewpoint):\n",
    "        myscore = opposcore = 0\n",
    "        for l in self.lines:\n",
    "            one=self.board[l[-1]]\n",
    "            if one!=0 and all(self.board[p]==one for p in l):\n",
    "                if one == viewpoint: myscore += 1\n",
    "                else: opposcore += 1\n",
    "        if myscore>opposcore: return 1\n",
    "        elif opposcore>myscore: return 0\n",
    "        return 0.5\n",
    "\n",
    "    def __repr__(self): return '\\n'.join(''.join(\"·XO\"[self.board[i*self.width+j]] for j in range(self.width)) for i in range(self.height))    \n",
    "    def key(self): return str(self.playerToMove)+''.join(\"·XO\"[e] for e in self.board)\n",
    "    def Reachable(self,key): return all(ch in '·12' or ch==key[i] for i,ch in enumerate(self.key()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "def genNet(oxo):\n",
    "    inp = tf.keras.layers.Input(shape=[oxo.height,oxo.width])\n",
    "    x = Reshape([oxo.height,oxo.width,1])(inp)\n",
    "    x = Activation('relu')(BatchNormalization(axis=3)(Conv2D(512, 2, padding='same')(x)))         # batch_size  x board_x x board_y x num_channels\n",
    "    x = Activation('relu')(BatchNormalization(axis=3)(Conv2D(512, 2, padding='same')(x)))         # batch_size  x board_x x board_y x num_channels\n",
    "    x = Activation('relu')(BatchNormalization(axis=3)(Conv2D(512, 2, padding='valid')(x)))        # batch_size  x (board_x-2) x (board_y-2) x num_channels\n",
    "    x = Activation('relu')(BatchNormalization(axis=3)(Conv2D(512, 2, padding='valid')(x)))        # batch_size  x (board_x-4) x (board_y-4) x num_channels\n",
    "    x = Flatten()(x)       \n",
    "    \n",
    "    s_fc1 = Dropout(.3)(Activation('relu')(BatchNormalization(axis=1)(Dense(1024)(x))))  # batch_size x 1024\n",
    "    s_fc2 = Dropout(.3)(Activation('relu')(BatchNormalization(axis=1)(Dense(512)(x))))   # batch_size x 1024\n",
    "    p = Dense(oxo.actionSize, activation='softmax', name='pi')(s_fc2)\n",
    "    v = Dense(1, activation='tanh', name='v')(s_fc2)\n",
    "    \n",
    "    m = tf.keras.Model(inputs=inp, outputs=[p,v])\n",
    "    m.compile(loss=['categorical_crossentropy','mean_squared_error'], optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12800 samples\n",
      "12800/12800 [==============================] - 44s 3ms/sample - loss: 0.5285 - pi_loss: 0.4986 - v_loss: 0.0299\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "\n",
    "game = OXO(5,5,4)\n",
    "# net = genNet(game)\n",
    "train_set = deque(maxlen=12800)\n",
    "mcts = MCTS(game,net)\n",
    "\n",
    "while True:\n",
    "    train_set += mcts.selfplay()\n",
    "    clear_output()\n",
    "    s,p,v=map(np.asarray,zip(*random.sample(train_set,len(train_set))))\n",
    "    net.fit(x = s, y = [p, v], verbose=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "game = OXO(5,5,4)\n",
    "mcts = MCTS(game,net)\n",
    "for s,p,v in mcts.selfplay():\n",
    "    print(s,'\\n',p.reshape(5,5),v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full game playout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = OXO(5,5,4)\n",
    "mcts = MCTS(game,net)\n",
    "while np.any(mcts.game.getValidMoves()):\n",
    "    m = mcts.search(timemax=10,verbose=1)\n",
    "    mcts.game.Move(m)\n",
    "    print(mcts.game, len(mcts.nodes))\n",
    "if mcts.game.GetResult(1) == 1:   print(\"Player 1(X) wins!\")\n",
    "elif mcts.game.GetResult(2) == 1: print(\"Player 2(O) wins!\")\n",
    "else: print(\"Nobody wins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Connect4](https://github.com/plkmo/AlphaZero_Connect4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Othello](https://github.com/suragnair/alpha-zero-general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
