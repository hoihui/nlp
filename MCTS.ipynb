{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math, random\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCTS is equivalent Monte Carlo control with UCB applied to the sub-MDP starting from the current state, where table lookup is represented by a tree. Since the action leads to deterministic results, $q(s,a)=v(s'_{\\rm a})$. $\\gamma=1$ and r=0 until endgame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barebone MCTS with UCT\n",
    "https://youtu.be/ItMutbeOHtc?t=3922, https://www.youtube.com/watch?v=Bm7zah_LrmE\n",
    "\n",
    "1. From each node (a node = a state of the board), repeat trying unexplored moves and rollout randomly unil gameover. The win/lose count is propagated back along the path (only above or at the level where new moves are being tried out -- for memory constraints) taken for each node\n",
    "2. when all moves of the node have been tried at least once, *select* the one to try based on **Upper Confidence Bound** UCB (mean value + C\\*uncertainty of the mean $\\propto\\sqrt{\\frac{\\log N_{\\rm visit}}{n_{\\rm child's visit}}}$). Repeat doing this until there is at least an untried move at the node\n",
    "3. repeat 1&2 until desired time/iteration limit, then select the best move at root node (current real situation of the board) based on *mean value* of each move\n",
    "\n",
    "4. consider some nodes may be reached from different ways; so keep the {move: child_node} dictionary. when selecting child node, return the corresponding move and child_node also (do not use parent of a node to backtrack)\n",
    "5. ONLY for terminating (acyclic) games\n",
    "6. Keep the nodes that (in principle) could be reached from the current state in the future. Game class need to implement `Reachable` wrt its key for this to work. Otherwise keep every node (memory...)\n",
    "7. prune tree from the leaf. If searched to the end game already, we know the value of node exactly at that point, and can know if previous state will definitely (not) move towards there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: [mcts.ai](http://mcts.ai/code/python.html) modified + reuse nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instance of game class is passed to `MCTS`'s `search` function, and must have:\n",
    "* `playerJustMoved`: 1 or 2\n",
    "* `GetMoves()`: returns list of (hashable) valid moves from current state\n",
    "* `Move(m)`: execute the passed in move (which is guaranteed to be chosen from `GetMoves()`)\n",
    "* `RollOut()`: randomly execuate the game until game over\n",
    "* `GetResult(viewpoint)`: (after game over) returns the reward (1 or 0) from the specified viewpoint (1 or 2 -- corresponding to playerJustMoved)\n",
    "* `key()`: returns a string fully and uniquely characterize the status of the game\n",
    "* [Optional]`Reachable(k)`: returns whether (True/False) the game could in principle reach the state represented by the passed-in key `k`, which was generated by the `key()` function of another state. If not provided, prune tree by deleting nodes not visited during a search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     122
    ]
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\" Wins is always from the viewpoint of playerJustMoved.\"\"\"\n",
    "    def __init__(self, state = None):\n",
    "        self.childNodes = {} # {move:node} the move that get *into* next node\n",
    "        self.wins = 0  #for the playerJustMoved\n",
    "        self.visits = 0\n",
    "        self.untriedMoves = state.GetMoves() # future child nodes\n",
    "        self.playerJustMoved = state.playerJustMoved # the only part of the state that the Node needs later\n",
    "        \n",
    "    def UCTSelectChild(self,explore=1):\n",
    "        \"\"\" Use the UCB1 formula to select a child node. Often a constant UCTK is applied so we have\n",
    "            lambda c: c.wins/c.visits + UCTK * sqrt(2*log(self.visits)/c.visits to vary the amount of\n",
    "            exploration versus exploitation. \n",
    "        \"\"\"\n",
    "        return max(list(self.childNodes.items()), \n",
    "                   key = lambda c: c[1].wins/c[1].visits + explore*math.sqrt(math.log(self.visits)/c[1].visits) )\n",
    "    \n",
    "    def AddChild(self, move, s, n = None):\n",
    "        \"\"\" Remove m from untriedMoves and add a new child node for this move. if provided, use that  \"\"\"\n",
    "        if n is None:\n",
    "            n = Node(state = s)\n",
    "        self.untriedMoves.remove(move)\n",
    "        self.childNodes[move] = n\n",
    "        return n\n",
    "    \n",
    "    def Update(self, result, visits=None):\n",
    "        \"\"\" update visit & win counts. (from the viewpoint of playerJustMoved) \"\"\"\n",
    "        self.visits += 1\n",
    "        self.wins += result # game results in the range [0.0, 1.0]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[W/V: {self.wins:6g}/{self.visits:6d} | UnXplrd: {len(self.untriedMoves)}] \"\n",
    "\n",
    "    def TreeToString(self, indent):\n",
    "        s = \"\\n\"+ \"| \"*indent + str(self)\n",
    "        s += ''.join(c.TreeToString(indent+1)+str(m) for m,c in self.childNodes.items())\n",
    "        return s\n",
    "\n",
    "    def ChildrenToString(self):        \n",
    "        return \"\\n\".join(f'{str(m):8s}|{c}' for m,c in sorted(self.childNodes.items(),key=lambda e: e[1].wins/e[1].visits))\n",
    "    \n",
    "class MCTS():   #reuses nodes\n",
    "    def __init__(self, explore=1, verbosity=0):\n",
    "        self.nodes = {}               #store all nodes previously explored\n",
    "        self.explore = explore\n",
    "        self.verbosity = verbosity\n",
    "        self.inf = float('inf')\n",
    "\n",
    "    def search(self, state, timemax=None, itermax=None):\n",
    "        \n",
    "        key = state.key()\n",
    "        if key not in self.nodes:\n",
    "            self.nodes[key] = Node(state = state)\n",
    "        self.rootnode = self.nodes[key]\n",
    "        \n",
    "        if 'Reachable' in dir(state): #pruning by (game provided) finding which node will be reachable\n",
    "            self.nodes = {k:v for k,v in self.nodes.items() if k==key or state.Reachable(k)}\n",
    "                    \n",
    "        if self.rootnode.untriedMoves or len(self.rootnode.childNodes)>1:  #unimportant -- determine when to stop\n",
    "            if itermax or timemax:\n",
    "                start=time.time()\n",
    "                i = 0\n",
    "                while (timemax is None or time.time()<start+timemax) and\\\n",
    "                      (itermax is None or i<itermax):\n",
    "                    i = i+100\n",
    "                    for _ in range(100):\n",
    "                        v=self.simulate(deepcopy(state),self.rootnode)\n",
    "                    if v==self.inf: break\n",
    "            else: #debug\n",
    "                while True:\n",
    "                    for _ in range(10000): self.simulate(deepcopy(state),self.rootnode)\n",
    "                    print(sum(c.visits for c in self.rootnode.childNodes.values()),\n",
    "                          sorted(list(self.rootnode.childNodes.items()), \n",
    "                              key = lambda c: -c[1].wins/c[1].visits ),\n",
    "                          end='\\r')\n",
    "                    \n",
    "        moveToChild, bestChild = self.rootnode.UCTSelectChild(explore=0)\n",
    "        if self.verbosity==2:   print(self.rootnode.TreeToString(0))\n",
    "        elif self.verbosity==1: print(self.rootnode.ChildrenToString())\n",
    "            \n",
    "        return moveToChild\n",
    "    \n",
    "    def simulate(self,state,node):\n",
    "        if node.untriedMoves == [] and node.childNodes != {}: #fully expanded, non-terminal\n",
    "            move,nnode = node.UCTSelectChild(self.explore) #descend (following UCB) \n",
    "            if nnode.wins==self.inf or nnode.wins==-self.inf: #if the best is -inf or inf already, can backprop\n",
    "                node.Update(-nnode.wins)\n",
    "                return -nnode.wins\n",
    "            state.Move(move)\n",
    "            v = self.simulate(state,nnode)\n",
    "            if v==-self.inf: v=0 # if v==-inf, next mover will not choose this branch as it leads to loss.\n",
    "                            # Note: other branch may have finite v as UCT  saw this branch as finite v before  simulation\n",
    "            node.Update(1-v)\n",
    "            return 1-v\n",
    "        elif node.untriedMoves != []: #not fully expanded: expand and then rollout\n",
    "            move = random.choice(node.untriedMoves) \n",
    "            state.Move(move)\n",
    "            k = state.key()\n",
    "            if k in self.nodes:\n",
    "                nnode = self.nodes[k]\n",
    "            else:\n",
    "                nnode = Node(state = state)\n",
    "                self.nodes[k] = nnode\n",
    "            node.AddChild(move,state,nnode)\n",
    "            state.RollOut()\n",
    "            v = state.GetResult(nnode.playerJustMoved) #not setting inf or -inf because there are indeterminism (unexplored moves)\n",
    "            nnode.Update(v)\n",
    "            node.Update(1-v)\n",
    "            return 1-v\n",
    "        elif node.childNodes == {}: #terminal\n",
    "            v = state.GetResult(node.playerJustMoved)\n",
    "            if v==1:    v=self.inf\n",
    "            elif v==0:  v=-self.inf\n",
    "            node.Update(v)\n",
    "            return v\n",
    "    \n",
    "    def __simulate(self,state,node): #old, iterative version\n",
    "        path = [node]\n",
    "        #descend (following UCB) to the first branch not fully expanded (some moves not tried), or reaching end of game\n",
    "        while node.untriedMoves == [] and node.childNodes != {}:\n",
    "            move,node = node.UCTSelectChild(self.explore)\n",
    "            if node.wins==float('inf') or node.wins==float('-inf'): #if the best is -inf or inf, can backprop already\n",
    "                path[-1].Update(-node.wins)\n",
    "                return\n",
    "            state.Move(move)\n",
    "            path += node,\n",
    "        \n",
    "        # if there are unexplored expand (add a childNode) and move the state into it \n",
    "        if node.untriedMoves != []: \n",
    "            move = random.choice(node.untriedMoves) \n",
    "            state.Move(move)\n",
    "            k = state.key()\n",
    "            if k in self.nodes:\n",
    "                nextnode = self.nodes[k]\n",
    "            else:\n",
    "                nextnode = Node(state = state)\n",
    "                \n",
    "            node.AddChild(move,state,nextnode)\n",
    "            self.nodes[k] = nextnode\n",
    "            node = nextnode\n",
    "            path += node,\n",
    "        elif node.childNodes == {}: #nothing unexplored and is terminal: delete this child for its parent if loss\n",
    "            reward = state.GetResult(node.playerJustMoved)\n",
    "            if reward==1:\n",
    "                node.Update(float('inf'))\n",
    "            elif reward==0:\n",
    "                node.Update(float('-inf'))\n",
    "\n",
    "        # Rollout to END of a game randomly (not expanding childNodes -- just want to estimate the newly added node's value)\n",
    "        state.RollOut()\n",
    "\n",
    "        # state is now terminal; backpropagate this game's result to its path's nodes' win counts\n",
    "        reward = state.GetResult(node.playerJustMoved)\n",
    "        for n in path:\n",
    "            if n.playerJustMoved == node.playerJustMoved:\n",
    "                n.Update(reward)\n",
    "            else:\n",
    "                n.Update(1-reward)\n",
    "        if self.prune: self.visitedNode|=set(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [m,n,k-game](https://en.wikipedia.org/wiki/M,n,k-game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#contains current state and who has last moved\n",
    "import itertools\n",
    "class OXOState:\n",
    "    def __init__(self,width=3,height=3,inarow=None,moves_per_round=None,end1=True): # game ends as one success\n",
    "        self.playerJustMoved = 2 #  (1) will have the first move\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.board = [0]*width*height # 0 = empty, 1 = player 1, 2 = player 2\n",
    "        self.empty = list(range(width*height))\n",
    "        self.moves_per_round = moves_per_round or 1\n",
    "        self.end1 = end1\n",
    "        \n",
    "        # winning lines\n",
    "        inarow = inarow or min(width,height)\n",
    "        self.lines = [tuple(range(i*width+j,i*width+j+inarow)) for i in range(0,height) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,(i+inarow)*width+j,width)) for i in range(0,height-inarow+1) for j in range(width)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width+1),width+1)) for i in range(height-inarow+1) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width-1),width-1)) for i in range(height-inarow+1) for j in range(inarow-1,width)]\n",
    "\n",
    "    def Move(self, move):\n",
    "        \"\"\" Update a state by carrying out the given move. Must also update playerJustMoved.  \"\"\"\n",
    "        self.playerJustMoved = 3 - self.playerJustMoved\n",
    "        for m in move:\n",
    "            self.board[m] = self.playerJustMoved\n",
    "            self.empty.remove(m)\n",
    "        if self.end1 and self.GetResult(self.playerJustMoved) in [0,1]:  \n",
    "            self.empty=[]\n",
    "        \n",
    "    def GetMoves(self): # must clone as Node use this return as untriedMoves  # return self.empty[:]\n",
    "        return list(itertools.combinations(self.empty,self.moves_per_round))\n",
    "    \n",
    "    def RollOut(self):\n",
    "        possibleMoves = self.GetMoves()\n",
    "        while possibleMoves:\n",
    "            self.Move(random.choice(possibleMoves))\n",
    "            possibleMoves = self.GetMoves()\n",
    "    \n",
    "    def GetResult(self, viewpoint):  # reward from `viewpoint`, in the range [0.0, 1.0]\n",
    "        myscore = opposcore = 0\n",
    "        for l in self.lines:\n",
    "            one=self.board[l[-1]]\n",
    "            if one!=0 and all(self.board[p]==one for p in l):\n",
    "                if one == viewpoint:\n",
    "                    myscore += 1\n",
    "                else:\n",
    "                    opposcore += 1\n",
    "        if myscore>opposcore: return 1\n",
    "        elif opposcore>myscore: return 0\n",
    "        return 0.5\n",
    "\n",
    "    def __repr__(self): # for output: 1 (X), 2 = (O)\n",
    "        s = ''\n",
    "        for left in range(0,self.width*self.height,self.width):\n",
    "            for sh in range(self.width): s+=\"·XO\"[self.board[left+sh]]\n",
    "            s+='\\n'\n",
    "        return s.strip()\n",
    "    \n",
    "    def key(self): #string containing all information for hashing the node\n",
    "        return str(self.playerJustMoved)+''.join(\"·XO\"[e] for e in self.board)\n",
    "    def Reachable(self,key):  #for pruning Tree\n",
    "        mykey = self.key()\n",
    "        return all(ch in '·12' or ch==key[i] for i,ch in enumerate(mykey))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fail to draw on 5,5,4, 2nd: after first player places at center, 2nd player should play at a position \"diagonal\" to the center (6,8,16,18). MCTS failed to identify these four as optimal until after ~10min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = OXOState(width=5,height=5,inarow=4)\n",
    "mcts = MCTS(verbosity=1,explore=1)\n",
    "state.Move((12,)) # after this, found (7,11,13,17) leads to sure loss after ? simulations\n",
    "state.Move((11,)) # after this, found sure win policy after 260663 simulations\n",
    "state.Move((16,)) # after this, found sure loss after 189564 simulations\n",
    "state.Move((8,))  # after this, found sure win policy after 35905 simulations\n",
    "state.Move((18,)) # after this, found sure loss after 25918 simulations\n",
    "state.Move((6,))  # after this, found sure win policy after 1601 simulations\n",
    "mcts.search(state,timemax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state = OXOState(width=3,height=3,inarow=3,moves_per_round=1,end1=True) #traditional\n",
    "# state = OXOState(width=5,height=5,inarow=4) #http://boulter.com/ttt/\n",
    "# state = OXOState(width=8,height=8,inarow=4,moves_per_round=2,end1=False) #http://www.atksolutions.com/games/tictactoedeluxe.html\n",
    "# state = OXOState(width=15,height=15,inarow=5) #Gomoku\n",
    "mcts = MCTS(verbosity=1,explore=1)\n",
    "while state.GetMoves():\n",
    "    if state.playerJustMoved==1: #computer plays 1st/2nd\n",
    "#         clear_output()\n",
    "        board=np.array([f'{(\"·XO\"[s] if s else str(pos)):2s}' for pos,s in enumerate(state.board)]).reshape(state.height,state.width)\n",
    "        print(board)\n",
    "        if state.key() in mcts.nodes:\n",
    "            n=mcts.nodes[state.key()]\n",
    "            print(n.ChildrenToString())\n",
    "            print(f'choose from: {state.GetMoves()[:10]}...',end='')\n",
    "        m = (int(input()),)   #2 moves (int(input()),int(input()))\n",
    "    else:\n",
    "        m = mcts.search(state,timemax=10)\n",
    "    state.Move(m)\n",
    "    print(state)\n",
    "    print(len(mcts.nodes))\n",
    "if state.GetResult(1) == 1:   print(\"Player 1(X) wins!\")\n",
    "elif state.GetResult(2) == 1: print(\"Player 2(O) wins!\")\n",
    "else: print(\"Nobody wins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ConnectNState:\n",
    "    def __init__(self,width=7,height=6,inarow=4):\n",
    "        self.playerJustMoved = 2\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.board = [0]*width*height\n",
    "        self.moves = list(range(width))\n",
    "        self.firstEmpty = [height-1]*width\n",
    "        \n",
    "        # winning lines\n",
    "        inarow = inarow or min(width,height)\n",
    "        self.lines = [tuple(range(i*width+j,i*width+j+inarow)) for i in range(0,height) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,(i+inarow)*width+j,width)) for i in range(0,height-inarow+1) for j in range(width)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width+1),width+1)) for i in range(height-inarow+1) for j in range(width-inarow+1)]+\\\n",
    "                     [tuple(range(i*width+j,i*width+j+inarow*(width-1),width-1)) for i in range(height-inarow+1) for j in range(inarow-1,width)]\n",
    "\n",
    "    def Move(self, move):  #move=column idx\n",
    "        assert move in self.moves\n",
    "        self.playerJustMoved = 3 - self.playerJustMoved\n",
    "        self.board[self.firstEmpty[move]*self.width+move]=self.playerJustMoved\n",
    "        self.firstEmpty[move] -= 1\n",
    "        if self.firstEmpty[move]<0:\n",
    "            self.moves.remove(move)\n",
    "        if self.GetResult(self.playerJustMoved) in [0,1]:  #indicate game ended as someone won\n",
    "            self.moves=[] \n",
    "        \n",
    "    def GetMoves(self):  # legal moves for next player. empty if game is over\n",
    "        return self.moves[:]\n",
    "    \n",
    "    def RollOut(self):\n",
    "        while self.moves:\n",
    "            self.Move(random.choice(self.moves))\n",
    "    \n",
    "    def GetResult(self, viewpoint):  # reward from `viewpoint`, in the range [0.0, 1.0]\n",
    "        for l in self.lines:\n",
    "            one=self.board[l[-1]]\n",
    "            if one!=0 and all(self.board[p]==one for p in l):\n",
    "                if one == viewpoint:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 0\n",
    "        return 0.5\n",
    "\n",
    "    def __repr__(self): # string representation: 1 (X), 2 = (O)\n",
    "        s = ''\n",
    "        for left in range(0,self.width*self.height,self.width):\n",
    "            for sh in range(self.width):\n",
    "                s+=\"·XO\"[self.board[left+sh]]\n",
    "            s+='\\n'\n",
    "        return s.strip()\n",
    "    def key(self): #string containing all information for hashing the node\n",
    "        return str(self.playerJustMoved)+''.join(\"·XO\"[e] for e in self.board)\n",
    "    def Reachable(self,key):  #for pruning Tree\n",
    "        mykey = self.key()\n",
    "        return all(ch in '12·' or ch==key[i] for i,ch in enumerate(mykey)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fails to deduce that the 5th move (1st player) should be at center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, [W/V:  45806/ 80549 | UnXplrd: 0] ), (6, [W/V: 38631.5/ 68198 | UnXplrd: 0] ), (2, [W/V: 27781.5/ 49461 | UnXplrd: 0] ), (4, [W/V: 27232.5/ 48510 | UnXplrd: 0] ), (3, [W/V: 20572.5/ 36958 | UnXplrd: 0] ), (1, [W/V: 18619.5/ 33560 | UnXplrd: 0] ), (5, [W/V: 17588.5/ 31764 | UnXplrd: 0] )]\r"
     ]
    }
   ],
   "source": [
    "state = ConnectNState(7,6,4) #https://connect4.gamesolver.org/\n",
    "for _ in range(4): state.Move(3)\n",
    "mcts = MCTS(verbosity=1,explore=2)\n",
    "while state.GetMoves():\n",
    "    if state.playerJustMoved==1:\n",
    "#         clear_output()\n",
    "        fn = lambda s: s if int(s)<7 else ''\n",
    "        board=np.array([f'{(\"·XO\"[s] if s else fn(str(pos))):2s}' for pos,s in enumerate(state.board)])\n",
    "        print(board.reshape(state.height,state.width))\n",
    "        if state.key() in mcts.nodes:\n",
    "            n=mcts.nodes[state.key()]\n",
    "            print(n.ChildrenToString())\n",
    "            print('choose from:',end='')\n",
    "        m = int(input(state.GetMoves()))\n",
    "    else:\n",
    "        m = mcts.search(state,timemax=None)\n",
    "    state.Move(m)\n",
    "    print(state)\n",
    "    print(len(mcts.nodes))\n",
    "if state.GetResult(1) == 1:   print(\"Player 1(X) wins!\")\n",
    "elif state.GetResult(2) == 1: print(\"Player 2(O) wins!\")\n",
    "else: print(\"Nobody wins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Othello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OthelloState:\n",
    "    def __init__(self, size = 8):  # size must be integral and even\n",
    "        self.playerJustMoved = 2\n",
    "        self.size = size\n",
    "        self.board = [] # 0 = empty, 1 = player 1, 2 = player 2\n",
    "        for y in range(self.size):\n",
    "            self.board.append([0]*size)\n",
    "        self.board[size//2][size//2] = self.board[size//2-1][size//2-1] = 2\n",
    "        self.board[size//2][size//2-1] = self.board[size//2-1][size//2] = 1\n",
    "        self.board = [e for l in self.board for e in l]\n",
    "\n",
    "    def Move(self, move):\n",
    "        if move is not None:\n",
    "            (x,y)=divmod(move,self.size)\n",
    "            assert self.IsOnBoard(x,y) and self.board[x*self.size+y] == 0\n",
    "            m = self.GetAllSandwichedCounters(x,y)\n",
    "            self.playerJustMoved = 3 - self.playerJustMoved\n",
    "            self.board[x*self.size+y] = self.playerJustMoved\n",
    "            for (a,b) in m:\n",
    "                self.board[a*self.size+b] = self.playerJustMoved\n",
    "        else: \n",
    "            self.playerJustMoved = 3 - self.playerJustMoved\n",
    "    \n",
    "    def GetMoves(self):\n",
    "        emptypos = [pos for pos,e in enumerate(self.board) if e==0]\n",
    "        if not emptypos:\n",
    "            return []\n",
    "        else:\n",
    "            viable = [pos for pos in emptypos if self.ExistsSandwiched(*divmod(pos,self.size))] \n",
    "            if viable:\n",
    "                return viable\n",
    "            else:  #need to check if opponent also has no viable pos\n",
    "                self.playerJustMoved = 3 - self.playerJustMoved\n",
    "                oppoViable = [pos for pos in emptypos if self.ExistsSandwiched(*divmod(pos,self.size))]\n",
    "                self.playerJustMoved = 3 - self.playerJustMoved\n",
    "                if oppoViable:\n",
    "                    return [None]\n",
    "                else:\n",
    "                    return []\n",
    "    \n",
    "    def RollOut(self):\n",
    "        emptypos = [pos for pos,e in enumerate(self.board) if e==0]\n",
    "        bad=0 \n",
    "        while emptypos:\n",
    "            random.shuffle(emptypos)\n",
    "            for pos in emptypos:\n",
    "                if self.ExistsSandwiched(*divmod(pos,self.size)):\n",
    "                    self.Move(pos)\n",
    "                    emptypos = [i for i,e in enumerate(self.board) if e==0]\n",
    "                    break\n",
    "            else:\n",
    "                if bad<2: #when bad=2, both side cannot play, game ends\n",
    "                    bad+=1\n",
    "                    self.Move(None)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    def AdjacentEnemyDirections(self,x,y):# Speeds up GetMoves by only considering squares which are adjacent to an enemy-occupied square.\n",
    "        return [(dx,dy) for (dx,dy) in [(0,+1),(+1,+1),(+1,0),(+1,-1),(0,-1),(-1,-1),(-1,0),(-1,+1)]\n",
    "                        if self.IsOnBoard(x+dx,y+dy) and self.board[(x+dx)*self.size+y+dy] == self.playerJustMoved]\n",
    "    \n",
    "    def ExistsSandwiched(self,x,y):# Is there at least one counter which would be flipped if my counter was placed at (x,y)? \n",
    "        for (dx,dy) in self.AdjacentEnemyDirections(x,y):\n",
    "            x1=x+dx\n",
    "            y1=y+dy\n",
    "            while self.IsOnBoard(x1,y1) and self.board[x1*self.size+y1] == self.playerJustMoved:\n",
    "                x1 += dx\n",
    "                y1 += dy\n",
    "            if self.IsOnBoard(x1,y1) and self.board[x1*self.size+y1] == 3 - self.playerJustMoved:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def GetAllSandwichedCounters(self, x, y):# Is (x,y) a possible move (i.e. opponent counters are sandwiched between (x,y) and my counter in some direction)?\n",
    "        sandwiched = []\n",
    "        for (dx,dy) in self.AdjacentEnemyDirections(x,y):\n",
    "            sandwiched.extend(self.SandwichedCounters(x,y,dx,dy))\n",
    "        return sandwiched\n",
    "\n",
    "    def SandwichedCounters(self, x, y, dx, dy):# Return the coordinates of all opponent counters sandwiched between (x,y) and my counter.\n",
    "        x += dx\n",
    "        y += dy\n",
    "        sandwiched = []\n",
    "        while self.IsOnBoard(x,y) and self.board[x*self.size+y] == self.playerJustMoved:\n",
    "            sandwiched.append((x,y))\n",
    "            x += dx\n",
    "            y += dy\n",
    "        if self.IsOnBoard(x,y) and self.board[x*self.size+y] == 3 - self.playerJustMoved:\n",
    "            return sandwiched\n",
    "        else:\n",
    "            return [] # nothing sandwiched\n",
    "\n",
    "    def IsOnBoard(self, x, y):\n",
    "        return x >= 0 and x < self.size and y >= 0 and y < self.size\n",
    "    \n",
    "    def GetResult(self, viewpoint): #after gameover\n",
    "        viewpointscore=oppositescore=0\n",
    "        for e in self.board:\n",
    "            if e==viewpoint: viewpointscore+=1\n",
    "            elif e==3-viewpoint: oppositescore+=1\n",
    "        if viewpointscore > oppositescore: return 1.0\n",
    "        elif oppositescore > viewpointscore: return 0.0\n",
    "        else: return 0.5 # draw\n",
    "\n",
    "    def __repr__(self):\n",
    "        s= \"\"\n",
    "        for x in range(self.size):\n",
    "            for y in range(self.size):\n",
    "                s += \"·XO\"[self.board[x*self.size+y]]\n",
    "            s += \"\\n\"\n",
    "        return s.strip()\n",
    "    def key(self): #string containing all information for hashing the node\n",
    "        return str(self.playerJustMoved)+''.join(\"·XO\"[e] for e in self.board)\n",
    "    def Reachable(self,key):  #for pruning Tree\n",
    "        mykey = self.key()\n",
    "        return key.count('·')<mykey.count('·') and \\\n",
    "               all(ch in '12·' or key[i]!='·' for i,ch in enumerate(mykey)) and\\\n",
    "               (mykey[1]=='·' or mykey[1]==key[1]) and\\\n",
    "               (mykey[self.size]=='·' or mykey[self.size]==key[self.size]) and\\\n",
    "               (mykey[-self.size]=='·' or mykey[-self.size]==key[-self.size]) and\\\n",
    "               (mykey[-1]=='·' or mykey[-1]==key[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* timemax=60 beats Reversu Difficult\n",
    "* timemax=15 beats Reversu Medium, lost to Reversu Difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['X ' 'X ' 'X ' 'X ' 'X ' 'X ' 'X ' 'X ']\n",
      " ['X ' 'X ' 'X ' 'X ' 'X ' 'X ' 'X ' 'X ']\n",
      " ['O ' 'X ' 'X ' 'X ' 'X ' 'O ' 'X ' 'X ']\n",
      " ['O ' 'O ' 'X ' 'X ' 'X ' 'X ' 'O ' 'X ']\n",
      " ['O ' 'O ' 'X ' 'O ' 'O ' 'O ' 'X ' 'X ']\n",
      " ['40' 'O ' 'X ' 'O ' 'X ' 'X ' 'X ' 'X ']\n",
      " ['48' 'X ' 'O ' 'X ' 'X ' 'X ' 'X ' 'X ']\n",
      " ['X ' 'X ' 'X ' 'X ' 'X ' 'X ' 'X ' 'X ']]\n",
      "48      |[W/V:   -inf/     4 | UnXplrd: 0] \n",
      "choose from:[48]48\n",
      "XXXXXXXX\n",
      "XXXXXXXX\n",
      "OXXXXOXX\n",
      "OOXXXXOX\n",
      "OOXOOOXX\n",
      "·OXOXXXX\n",
      "OOOXXXXX\n",
      "XXXXXXXX\n",
      "455\n",
      "40      |[W/V:    inf/     4 | UnXplrd: 0] \n",
      "XXXXXXXX\n",
      "XXXXXXXX\n",
      "XXXXXOXX\n",
      "XOXXXXOX\n",
      "XXXOOOXX\n",
      "XXXOXXXX\n",
      "XXOXXXXX\n",
      "XXXXXXXX\n",
      "38\n",
      "Player 1(X) wins!\n"
     ]
    }
   ],
   "source": [
    "# state = OthelloState(8)\n",
    "# mcts = MCTS(verbosity=1)\n",
    "while state.GetMoves():\n",
    "    if state.playerJustMoved==1:\n",
    "        clear_output()\n",
    "        board=np.array([f'{(\"·XO\"[e] if e else str(p)):2s}' for p,e in enumerate(state.board)]).reshape(8,8)\n",
    "        print(board)\n",
    "        if state.key() in mcts.nodes:\n",
    "            print(mcts.nodes[state.key()].ChildrenToString())\n",
    "            print('choose from:',end='')\n",
    "        moves = state.GetMoves()\n",
    "        if moves[0] is None: m = None\n",
    "        else: m=int(input(moves))\n",
    "    else:\n",
    "        m = mcts.search(state,timemax=1+len(list(filter(None,state.board)))*0 )  #len...=number of pieces on board\n",
    "    state.Move(m)\n",
    "    print(state)\n",
    "    print(len(mcts.nodes))\n",
    "if state.GetResult(1) == 1:   print(\"Player 1(X) wins!\")\n",
    "elif state.GetResult(2) == 1: print(\"Player 2(O) wins!\")\n",
    "else: print(\"Nobody wins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero-style (guide tree search by policy+value network)\n",
    "\n",
    "https://www.youtube.com/watch?v=ld28AU7DDB4\n",
    "* The uncertainty term used in UCB is replaced by **Polynomial Upper Confidence Trees** PUCT $\\propto P(s_i|s)\\frac{\\sqrt{N}}{1+n_i}$ (where N is the total visits of current state s, and n_i are visit counts of each of the next possible nodes). $P(s_i|s)$ is a probability output by policy network given current state\n",
    "* Rollout replaced by the value estimation of the current state by the network. For a newly-expanded child node (c), use value network to compute all the values of its possible child nodes (c's c), used for computing the mean of the current (c) node, with weights given by the policy network.\n",
    "* In AlphaGo, policy network is trained with human expert positions. Then policy network is then used to play against itself to generate positions + target (win/loss) for training the value network\n",
    "* AlphaZero combines policy and value network into a single network. Repeat:\n",
    "  1. training examples (state,policy of next move,win/loss) are generated by MCTS, used to train the policy+value network.\n",
    "  2. Use the network trained to guide MCTS\n",
    "  \n",
    "Other tweaks\n",
    "* in the PUCT, normalize (sum of all=1) and *then* exponentiate all counts before putting into formula $N^{1/\\tau}$ and $n_i^{1/\\tau}$, where $\\tau=1$ for the first 10-100 moves (exploratory) and ~0 for later moves (only choose the best).\n",
    "* After each iteration, pit against previous version of the net to make sure it has really improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train net using (states,policies,values) given by the self-plays of MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xy += mcts.selfplay()\n",
    "net.train(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCTS given guidance from Net, generates (states,policies,values) through self-play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS():\n",
    "    def __init__(self, game, net):\n",
    "        self.game = game\n",
    "        self.net = net\n",
    "        self.Qsa = {}       # stores Q values for s,a (as defined in the paper)\n",
    "        self.Nsa = {}       # stores #times edge s,a was visited\n",
    "        self.Ns = {}        # stores #times board s was visited\n",
    "        self.Ps = {}        # stores initial policy (returned by neural net)\n",
    "\n",
    "        self.Es = {}        # stores game.getGameEnded ended for board s\n",
    "        self.Vs = {}        # stores game.getValidMoves for board s\n",
    "\n",
    "    def getActionProb(self, canonicalBoard, temp=1):\n",
    "        \"\"\"\n",
    "        This function performs numMCTSSims simulations of MCTS starting from\n",
    "        canonicalBoard.\n",
    "        Returns:\n",
    "            probs: a policy vector where the probability of the ith action is\n",
    "                   proportional to Nsa[(s,a)]**(1./temp)\n",
    "        \"\"\"\n",
    "        for i in range(self.args.numMCTSSims):\n",
    "            self.search(canonicalBoard)\n",
    "\n",
    "        s = self.game.stringRepresentation(canonicalBoard)\n",
    "        counts = [self.Nsa[(s,a)] if (s,a) in self.Nsa else 0 for a in range(self.game.getActionSize())]\n",
    "\n",
    "        if temp==0:\n",
    "            bestA = np.argmax(counts)\n",
    "            probs = [0]*len(counts)\n",
    "            probs[bestA]=1\n",
    "            return probs\n",
    "\n",
    "        counts = [x**(1./temp) for x in counts]\n",
    "        probs = [x/float(sum(counts)) for x in counts]\n",
    "        return probs\n",
    "\n",
    "\n",
    "    def search(self, canonicalBoard):\n",
    "        \"\"\"\n",
    "        This function performs one iteration of MCTS. It is recursively called\n",
    "        till a leaf node is found. The action chosen at each node is one that\n",
    "        has the maximum upper confidence bound as in the paper.\n",
    "        Once a leaf node is found, the neural network is called to return an\n",
    "        initial policy P and a value v for the state. This value is propogated\n",
    "        up the search path. In case the leaf node is a terminal state, the\n",
    "        outcome is propogated up the search path. The values of Ns, Nsa, Qsa are\n",
    "        updated.\n",
    "        NOTE: the return values are the negative of the value of the current\n",
    "        state. This is done since v is in [-1,1] and if v is the value of a\n",
    "        state for the current player, then its value is -v for the other player.\n",
    "        Returns:\n",
    "            v: the negative of the value of the current canonicalBoard\n",
    "        \"\"\"\n",
    "\n",
    "        s = self.game.stringRepresentation(canonicalBoard)\n",
    "\n",
    "        if s not in self.Es:\n",
    "            self.Es[s] = self.game.getGameEnded(canonicalBoard, 1)\n",
    "        if self.Es[s]!=0:\n",
    "            # terminal node\n",
    "            return -self.Es[s]\n",
    "\n",
    "        if s not in self.Ps:\n",
    "            # leaf node\n",
    "            self.Ps[s], v = self.nnet.predict(canonicalBoard)\n",
    "            valids = self.game.getValidMoves(canonicalBoard, 1)\n",
    "            self.Ps[s] = self.Ps[s]*valids      # masking invalid moves\n",
    "            sum_Ps_s = np.sum(self.Ps[s])\n",
    "            if sum_Ps_s > 0:\n",
    "                self.Ps[s] /= sum_Ps_s    # renormalize\n",
    "            else:\n",
    "                # if all valid moves were masked make all valid moves equally probable\n",
    "                \n",
    "                # NB! All valid moves may be masked if either your NNet architecture is insufficient or you've get overfitting or something else.\n",
    "                # If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.   \n",
    "                print(\"All valid moves were masked, do workaround.\")\n",
    "                self.Ps[s] = self.Ps[s] + valids\n",
    "                self.Ps[s] /= np.sum(self.Ps[s])\n",
    "\n",
    "            self.Vs[s] = valids\n",
    "            self.Ns[s] = 0\n",
    "            return -v\n",
    "\n",
    "        valids = self.Vs[s]\n",
    "        cur_best = -float('inf')\n",
    "        best_act = -1\n",
    "\n",
    "        # pick the action with the highest upper confidence bound\n",
    "        for a in range(self.game.getActionSize()):\n",
    "            if valids[a]:\n",
    "                if (s,a) in self.Qsa:\n",
    "                    u = self.Qsa[(s,a)] + self.args.cpuct*self.Ps[s][a]*math.sqrt(self.Ns[s])/(1+self.Nsa[(s,a)])\n",
    "                else:\n",
    "                    u = self.args.cpuct*self.Ps[s][a]*math.sqrt(self.Ns[s] + EPS)     # Q = 0 ?\n",
    "\n",
    "                if u > cur_best:\n",
    "                    cur_best = u\n",
    "                    best_act = a\n",
    "\n",
    "        a = best_act\n",
    "        next_s, next_player = self.game.getNextState(canonicalBoard, 1, a)\n",
    "        next_s = self.game.getCanonicalForm(next_s, next_player)\n",
    "\n",
    "        v = self.search(next_s)\n",
    "\n",
    "        if (s,a) in self.Qsa:\n",
    "            self.Qsa[(s,a)] = (self.Nsa[(s,a)]*self.Qsa[(s,a)] + v)/(self.Nsa[(s,a)]+1)\n",
    "            self.Nsa[(s,a)] += 1\n",
    "\n",
    "        else:\n",
    "            self.Qsa[(s,a)] = v\n",
    "            self.Nsa[(s,a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "return -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCTS using trained Net: given state, generate next move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Game` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Connect4](https://github.com/plkmo/AlphaZero_Connect4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Othello](https://github.com/suragnair/alpha-zero-general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
