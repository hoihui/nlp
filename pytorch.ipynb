{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.1.0.post2', False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip3 install -U torch torchvision\n",
    "import torch\n",
    "torch.manual_seed(7)\n",
    "torch.__version__, torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.xxx_()` means inplace function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.udacity.com/course/deep-learning-pytorch--ud188  ,  https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5), 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(5)\n",
    "x, x.item()            # convert to python scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5, dtype=torch.uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.ByteTensor) # typecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.new((3,4,5))   #.new() Constructs a new tensor of the same data type as self tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Alegra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908],\n",
      "        [-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]]) tensor([[0.3177, 0.1328, 0.1373, 0.2405, 1.3955],\n",
      "        [1.3470, 2.4382, 0.2028, 2.4505, 2.0256]]) tensor([[1.7792]])\n"
     ]
    }
   ],
   "source": [
    "features = torch.randn((2,5)) #tensor of size (2,5)\n",
    "weights = torch.randn_like(features)\n",
    "bias = torch.randn((1,1))\n",
    "print(features,weights,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(features,1).shape # add a dim of size 1 at the indicated dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908],\n",
       "        [-0.8948, -0.3556,  1.2324,  0.1382, -1.6822],\n",
       "        [ 0.3177,  0.1328,  0.1373,  0.2405,  1.3955],\n",
       "        [ 1.3470,  2.4382,  0.2028,  2.4505,  2.0256]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((features,weights),0)  # concat along axis 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9690, 1.5379]) tensor([0, 0]) tensor([[ 0.9690, -0.3885, -0.5442,  0.7239, -0.4055],\n",
      "        [ 1.5379,  1.2246, -1.2083, -0.2410,  0.9073]])\n"
     ]
    }
   ],
   "source": [
    "prob,pred = torch.max(features,1) #aling 2nd axis\n",
    "print(prob,pred,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9796]])\n",
      "tensor([[-1.9796]])\n",
      "tensor([[-1.9796]])\n",
      "tensor([[-1.9796]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication must have (ncols from 1st = nrows from 2nd)\n",
    "print(torch.mm(features,weights.transpose(0,1)))  #args are dimenions to swap\n",
    "print(torch.mm(features,weights.reshape(5,1))) #args are new nrow,ncol\n",
    "print(torch.mm(features,weights.resize_(5,1))) #args are new nrow,ncol; if different numel, remove or add (uninitialized)\n",
    "print(torch.mm(features,weights.view(5,1))) #.view returns new tensor; can use -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9552]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1 + torch.exp(torch.sum(features * weights) + bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.zero_(0) #fill self inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3915, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "y = x*x\n",
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9434, -0.2670],\n",
      "        [ 0.6160, -0.2253]])\n",
      "tensor([[ 0.9434, -0.2670],\n",
      "        [ 0.6160, -0.2253]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proving $\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    #tensors generated here with have no grad info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To/from Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory is shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2744, 0.6924],\n",
      "        [0.9054, 0.0106]], dtype=torch.float64)\n",
      "[[0.2743871  0.69241128]\n",
      " [0.90539865 0.01060206]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(2,2)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54877421, 1.38482256],\n",
       "       [1.8107973 , 0.02120412]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mul_(2) # inplace multiplication\n",
    "a # shows that memory is shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1373241 , 0.24054612],\n",
       "       [1.3954508 , 1.3470227 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "# x.numpy()  # Can't call numpy() on Variable that requires grad\n",
    "x.detach().numpy()\n",
    "#x.data equiv to x.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/torchvision/datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image transformations: http://pytorch.org/docs/master/torchvision/transforms.html\n",
    "* `transforms.Resize(255)`: \n",
    "* `transforms.CenterCrop(224)`: \n",
    "* `transforms.ToTensor()`: to PyTorch tensors\n",
    "* `transforms.RandomRotation(30)`: add randomness to improve network's robustness (different for each iteration); for test data, don't add randomness\n",
    "* `transforms.RandomResizedCrop(224)`\n",
    "* `transforms.RandomHorizontalFlip()`\n",
    "* `transforms.Normalize((0.5,), (0.5,))`: mean and std for each channel:  `(input[channel] - mean[channel]) / std[channel]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then call:\n",
    "\n",
    "`datasets.ImageFolder` or `datasets.DATASETNAME`\n",
    "\n",
    "labels are automatically set to subfolder names inside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create generator that go through batches:\n",
    "\n",
    "`dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)`\n",
    "\n",
    "can set `shuffle=False` and set `sampler=torch.utils.data.sampler.SubsetRandomSampler(idx)` to specify which indices to sample (for separating train/val sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "dataset = datasets.ImageFolder('path/to/datafolder', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `datasets.MNIST`\n",
    "* `datasets.FashionMNIST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# image transform pipeline\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)), \n",
    "                               ])\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)   # control train/test on train kw\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/',  download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)  #generator\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)  #generator\n",
    "\n",
    "images, labels = next(iter(trainloader))  #first batch of 64\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cats/Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_data = datasets.ImageFolder('~/.pytorch/catdog', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder('~/.pytorch/catdog', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loaders` are iterators which returns `X,y` tuples for each loop, where labels `y` are derived from the subdirectories in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purely functional operations (without parameters/weights/bias) can just use torch.nn.functional in place of nn elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.hidden  = nn.Linear(784, 256)  # can access weights on .hidden.weight, .hidden.bias\n",
    "        self.output  = nn.Linear(256, 10)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)    # dim=1 calculates softmax across the columns\n",
    "        # self.modules() iterates through all elements\n",
    "    def forward(self, x):    # x is 2D: batchsize*inputdim\n",
    "#         x = x.reshape(x.shape[0],784)  #make sure dimensions agree\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)  # equiv. x = F.sigmoid(x); can also use like F.relu(x), etc...\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)  # equiv. x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax()\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[ 0.0090,  0.0049,  0.0174,  ...,  0.0113,  0.0034, -0.0345],\n",
      "        [-0.0040,  0.0227, -0.0046,  ...,  0.0222,  0.0083,  0.0184],\n",
      "        [ 0.0272,  0.0153,  0.0144,  ..., -0.0326, -0.0300, -0.0187],\n",
      "        ...,\n",
      "        [ 0.0121, -0.0057,  0.0253,  ...,  0.0134, -0.0122,  0.0132],\n",
      "        [-0.0024,  0.0019,  0.0210,  ..., -0.0086,  0.0262, -0.0278],\n",
      "        [-0.0159,  0.0262,  0.0044,  ...,  0.0153,  0.0173, -0.0299]],\n",
      "       requires_grad=True)\n",
      "OrderedDict([('hidden', Linear(in_features=784, out_features=256, bias=True)), ('output', Linear(in_features=256, out_features=10, bias=True)), ('sigmoid', Sigmoid()), ('softmax', Softmax())])\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "print(model)\n",
    "print(model.hidden.weight)\n",
    "print(model._modules)   # An OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of `forward` member functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = self.dropout(F.relu(self.fc1(x)))    # self.dropout = nn.Dropout(p=0.2)\n",
    "    x = self.dropout(F.relu(self.fc2(x)))\n",
    "    x = F.log_softmax(self.fc2(x), dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access member variable to fill them (`_` indicates in-place):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0043, -0.0091, -0.0058,  ...,  0.0042, -0.0053,  0.0221],\n",
       "        [-0.0003,  0.0132, -0.0091,  ..., -0.0125,  0.0159, -0.0008],\n",
       "        [-0.0031, -0.0008, -0.0077,  ..., -0.0015, -0.0029, -0.0040],\n",
       "        ...,\n",
       "        [-0.0005, -0.0059,  0.0011,  ...,  0.0070,  0.0059,  0.0035],\n",
       "        [-0.0078, -0.0068,  0.0070,  ..., -0.0011,  0.0042,  0.0003],\n",
       "        [ 0.0046,  0.0101,  0.0144,  ..., -0.0104,  0.0091, -0.0217]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden.bias.data.fill_(0)           # equiv nn.init.constant_(model.hidden.bias,0)\n",
    "model.output.weight.data.normal_(0.0,1.0)   \n",
    "model.output.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, weights are uniform-initialized in the range [-y,y] where $y=1/\\sqrt{\\rm n_{input}}$\n",
    "\n",
    "The general rule for setting the weights in a neural network is to set them to be close to zero without being too small. \n",
    "> Good practice is to start your weights in the range of $[-y, y]$ where $y=1/\\sqrt{n}$  \n",
    "($n$ is the number of inputs to a given neuron)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=images.view(64, -1)  #originally 64x1x28x28\n",
    "model.forward(images)  #forward all images\n",
    "model(images) #equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using nn. without class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 10),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model[0])  #accessing element\n",
    "# model.forward(images)     # equiv model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(784, 256)),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('output', nn.Linear(256, 10)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "print(model[0].bias)    # accessing elements\n",
    "print(model.fc1.bias)   # accessing elements\n",
    "# model.forward(images)    # equiv model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Binay\n",
    "  * return a single number as output with `BCEWithLogitsLoss`, or\n",
    "  * return a probability as output with `BCELoss`\n",
    "* Multiclass\n",
    "  * return multiple numbers (eg. from `nn.Linear` output) with `CrossEntropyLoss`, or\n",
    "  * return multiple probabilities (eg. from `nn.LogSoftmax` output) with `NLLLoss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3173, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 256),  #could also use class or OrderedDict\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "images = images.view(64, -1)              #originally 64x1x28x28\n",
    "loss = criterion( model(images), labels)  #averaged over the batch\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first layer grad Before backward pass: \n",
      " None\n",
      "first layer grad After backward pass: \n",
      " tensor([[-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
      "        [-0.0058, -0.0058, -0.0058,  ..., -0.0058, -0.0058, -0.0058],\n",
      "        [-0.0059, -0.0059, -0.0059,  ..., -0.0059, -0.0059, -0.0059],\n",
      "        ...,\n",
      "        [-0.0012, -0.0012, -0.0012,  ..., -0.0012, -0.0012, -0.0012],\n",
      "        [-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
      "        [ 0.0038,  0.0038,  0.0038,  ...,  0.0038,  0.0038,  0.0038]])\n"
     ]
    }
   ],
   "source": [
    "print('first layer grad Before backward pass: \\n', model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('first layer grad After backward pass: \\n', model[0].weight.grad)\n",
    "nn.utils.clip_grad_norm_(model.parameters(), 5.0)   # gradient clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pytorch.org/docs/master/optim.html\n",
    "* `optim.SGD`\n",
    "* `optim.Adam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0225,  0.0054, -0.0342,  ..., -0.0061,  0.0087,  0.0269],\n",
      "        [-0.0331,  0.0253,  0.0078,  ...,  0.0262,  0.0045, -0.0281],\n",
      "        [-0.0069,  0.0357, -0.0105,  ...,  0.0260,  0.0166,  0.0045],\n",
      "        ...,\n",
      "        [ 0.0043, -0.0352,  0.0160,  ...,  0.0255, -0.0023, -0.0298],\n",
      "        [ 0.0159, -0.0356, -0.0056,  ...,  0.0277,  0.0312,  0.0060],\n",
      "        [-0.0139,  0.0074,  0.0274,  ..., -0.0272, -0.0031, -0.0049]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-7.0587e-05, -7.0587e-05, -7.0587e-05,  ..., -7.0587e-05,\n",
      "         -7.0587e-05, -7.0587e-05],\n",
      "        [-4.9133e-03, -4.9133e-03, -4.9133e-03,  ..., -4.9133e-03,\n",
      "         -4.9133e-03, -4.9133e-03],\n",
      "        [-6.5717e-03, -6.5717e-03, -6.5717e-03,  ..., -6.5717e-03,\n",
      "         -6.5717e-03, -6.5717e-03],\n",
      "        ...,\n",
      "        [-5.8080e-04, -5.8080e-04, -5.8080e-04,  ..., -5.8080e-04,\n",
      "         -5.8080e-04, -5.8080e-04],\n",
      "        [-1.1184e-03, -1.1184e-03, -1.1184e-03,  ..., -1.1184e-03,\n",
      "         -1.1184e-03, -1.1184e-03],\n",
      "        [ 2.5707e-03,  2.5707e-03,  2.5707e-03,  ...,  2.5707e-03,\n",
      "          2.5707e-03,  2.5707e-03]])\n"
     ]
    }
   ],
   "source": [
    "# One step\n",
    "optimizer.zero_grad()                   # gradients are accumulated -- clear first\n",
    "loss = criterion(model(images), labels) # forward a batch\n",
    "loss.backward()\n",
    "# print(model[0].weight.grad)           # get the grad of parameters\n",
    "print('Initial weights - ', model[0].weight)\n",
    "optimizer.step()                        # update params with accumulated grad\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9859724194129139\n",
      "Training loss: 0.44501842942827546\n",
      "Training loss: 0.3749764274432461\n",
      "Training loss: 0.34324646042163437\n",
      "Training loss: 0.3232783184154456\n"
     ]
    }
   ],
   "source": [
    "# Full epochs\n",
    "for epoch in range(5):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:        \n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()                     # empty grad\n",
    "        loss = criterion(model(images), labels)   # forward\n",
    "        loss.backward()                           # backward        \n",
    "        optimizer.step()                          # update params with accumulated grad\n",
    "        \n",
    "        running_loss += loss.item()               # loss value itself??\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With early stopping\n",
    "import tempfile                    # tempfile for saving model\n",
    "_,weightsfile=tempfile.mkstemp()\n",
    "#####.....\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), weightsfile)\n",
    "    else:\n",
    "        epochs_without_improvement+=1\n",
    "    if epochs_without_improvement>patience:\n",
    "        break\n",
    "model.load_state_dict(torch.load(weightsfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.cuda() #move to cuda\n",
    "# model.cpu()  #move back to cpu\n",
    "model.to(device)\n",
    "images=images.to(device)  #is not inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `with torch.no_grad()`:  no grad tracking\n",
    "* `model.eval()`        :  zero dropout probability\n",
    "* `model.train()`       :  back to nonzero original dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5433e-01, 1.0443e-03, 3.7916e-01, 5.2210e-02, 3.2306e-04, 1.2050e-02,\n",
      "        3.9326e-01, 2.8806e-04, 7.2790e-03, 5.5042e-05])\n",
      "torch.return_types.topk(\n",
      "values=tensor([[0.3933, 0.3792],\n",
      "        [0.9888, 0.0055],\n",
      "        [0.9653, 0.0344]]),\n",
      "indices=tensor([[6, 2],\n",
      "        [6, 2],\n",
      "        [7, 9]]))\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "with torch.no_grad():             # tells torch does not need to keep track of grad\n",
    "    model.eval()                  # .eval() mode sets dropout probability to zero\n",
    "    prob=torch.exp(model(images)) # The last layer is LogSoftmax, not Softmax\n",
    "model.train()                     # opposite of .eval()\n",
    "    \n",
    "print(prob[0])\n",
    "top_p, top_class = prob[:3].topk(2,dim=1)     # top-k most likely probability and the predicted classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test LogLoss:  0.31288541873285514\n",
      "Test Accuracy: 0.9099313616752625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test\n",
    "running_loss = 0\n",
    "running_acc = 0\n",
    "for images, labels in testloader:\n",
    "    images = images.view(images.shape[0], -1)\n",
    "    with torch.no_grad():             # tells torch does not need to keep track of grad\n",
    "        out = model(images)           # forward\n",
    "        \n",
    "    loss = criterion(out, labels)     \n",
    "    prob = torch.exp(out)\n",
    "    top_p, top_class = prob.topk(1, dim=1)\n",
    "    equals = (top_class == labels.view(*top_class.shape))\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    running_acc += torch.mean(equals.type(torch.FloatTensor))   #cast torch.ByteTensor to torch.FloatTensor for taking .mean()\n",
    "\n",
    "print(f\"Test LogLoss:  {running_loss/len(trainloader)}\")\n",
    "print(f\"Test Accuracy: {running_acc/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save / Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict() # to ordered dict\n",
    "torch.save(model.state_dict(), 'filename')      # save\n",
    "model.load_state_dict( torch.load('filename') ) # load; \"model\" variable must have the same architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to manually build a dictionary with all the information you need to compeletely rebuild the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/torchvision/models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most model has `classifier` and `features` part.\n",
    "\n",
    "For transfer learning, turn of grad for `features` part and attach custom classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "model = models.densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old: Linear(in_features=1024, out_features=1000, bias=True)\n",
      "new: Sequential(\n",
      "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (output): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():      # Freeze parameters of the feature detector\n",
    "    param.requires_grad = False\n",
    "    \n",
    "print(f\"old: {model.classifier}\")     # seeing the input is 1024, we need to match it in our own classifier\n",
    "from collections import OrderedDict   # create our own (binary) classifier\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 256)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(256, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))    \n",
    "model.classifier = classifier\n",
    "print(f\"new: {model.classifier}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "192px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
