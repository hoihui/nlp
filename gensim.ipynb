{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://radimrehurek.com/gensim/tutorial.html\">Tutorials</a><br/>\n",
    "<a href=\"https://radimrehurek.com/gensim/apiref.html\">API</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#conda install -c conda-forge gensim\n",
    "#for version 3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenization, stemming, etc... not handled by package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token2id: {'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n",
      "doc2bow: [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(common_texts) #inputs iterator (list, file object, ...) of words\n",
    "print('token2id:', dictionary.token2id) #word mapped to just id\n",
    "print('doc2bow:', dictionary.doc2bow(common_texts[1])) #tuple (id,freq), ignoring those with 0 freq\n",
    "# dictionary.save(pathtofile)\n",
    "# dictionary=corpora.Dictionary.load(pathtofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus = list (iterator) of bow (list of tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus=[dictionary.doc2bow(linelist) for linelist in common_texts]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf (term frequencyâ€“inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied to one doc: [(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "applied to whole: [(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)]\n",
      "[(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus) #transforms from bow (id,freq) to (id,tf x idf)  -- has no params\n",
    "print('applied to one doc:', tfidf[corpus[0]])\n",
    "print('applied to whole:', '\\n'.join(map(str,tfidf[corpus])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a href=\"https://radimrehurek.com/gensim/models/lsimodel.html#module-gensim.models.lsimodel\">lsi (Latent Semantic Indexing)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi = models.LsiModel(tfidf[corpus], id2word=dictionary, num_topics=2) #inputs either bow or tfidf model\n",
    "lsi.print_topics(2) #print words 'belonging' to each topic\n",
    "# lsi.save(pathtofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a href=\"https://radimrehurek.com/gensim/models/ldamodel.html\">lda (Latent Dirichlet Allocation)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.8963071), (1, 0.048678253), (2, 0.055014614)]\n",
      "0 [(0, 0.82634884), (1, 0.08513247), (2, 0.08851871)]\n",
      "1 [(0, 0.89627016), (1, 0.048678327), (2, 0.05505152)]\n",
      "2 [(0, 0.8572984), (1, 0.06803836), (2, 0.07466328)]\n",
      "3 [(0, 0.7829753), (1, 0.06865222), (2, 0.14837246)]\n",
      "4 [(0, 0.81499547), (1, 0.08530275), (2, 0.09970176)]\n",
      "5 [(0, 0.16784121), (1, 0.65781194), (2, 0.17434685)]\n",
      "6 [(0, 0.11177107), (1, 0.7646773), (2, 0.123551615)]\n",
      "7 [(0, 0.084061265), (1, 0.37287787), (2, 0.5430609)]\n",
      "8 [(0, 0.08876538), (1, 0.09079955), (2, 0.8204351)]\n"
     ]
    }
   ],
   "source": [
    "lda=models.LdaModel(corpus,id2word=dictionary,num_topics=3) #inputs bow\n",
    "print(lda[corpus[1]]) #distribution of topics\n",
    "for i,l in enumerate(lda[corpus]): #distribution of topics for all doc\n",
    "    print(i,l)\n",
    "lda.print_topics()\n",
    "lda.update(corpus) #update (online training) with more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.185*\"user\" + 0.184*\"response\" + 0.184*\"time\" + 0.116*\"system\" + 0.101*\"survey\" + 0.100*\"computer\" + 0.032*\"trees\" + 0.023*\"eps\" + 0.023*\"human\" + 0.018*\"graph\"'),\n",
       " (1,\n",
       "  '0.284*\"graph\" + 0.268*\"trees\" + 0.195*\"minors\" + 0.106*\"survey\" + 0.019*\"system\" + 0.019*\"user\" + 0.018*\"eps\" + 0.018*\"human\" + 0.018*\"interface\" + 0.018*\"response\"'),\n",
       " (2,\n",
       "  '0.230*\"system\" + 0.167*\"interface\" + 0.162*\"human\" + 0.162*\"eps\" + 0.092*\"computer\" + 0.091*\"user\" + 0.017*\"trees\" + 0.016*\"time\" + 0.016*\"graph\" + 0.016*\"survey\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a href=\"https://radimrehurek.com/gensim/models/hdpmodel.html\">hdp (Hierarchical Dirichlet Process)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.426*minors + 0.130*survey + 0.115*human + 0.070*interface + 0.063*computer + 0.052*time + 0.031*trees + 0.027*graph + 0.026*system + 0.025*user'),\n",
       " (1,\n",
       "  '0.292*system + 0.116*user + 0.115*minors + 0.099*graph + 0.098*eps + 0.081*time + 0.077*response + 0.060*computer + 0.028*human + 0.021*survey'),\n",
       " (2,\n",
       "  '0.383*eps + 0.215*interface + 0.061*human + 0.058*survey + 0.054*user + 0.040*trees + 0.036*response + 0.036*minors + 0.036*graph + 0.029*time')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdp = models.HdpModel(corpus, id2word=dictionary)\n",
    "hdp.print_topics(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: with a courpus and a query string, find the simiarities of each doc w.r.t. the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4618210045327153), (1, -0.0700276652789999)]\n",
      "[ 0.998093    0.93748635  0.9984453   0.9865886   0.90755945 -0.12416792\n",
      " -0.10639259 -0.09879464  0.05004176]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "from gensim import similarities\n",
    "\n",
    "#build lsi space from the corpus\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "\n",
    "#embed query in lsi space\n",
    "query = ['human','computer','interaction']\n",
    "query_vec = lsi[dictionary.doc2bow(query)]  \n",
    "print(query_vec)\n",
    "\n",
    "# transform corpus to LSI space and index it\n",
    "index = similarities.MatrixSimilarity(lsi[corpus]) #or use similarities.Similarity class for large corpus\n",
    "# index.save()\n",
    "# index=similarities.MatrixSimilarity.load()\n",
    "\n",
    "# perform a similarity query against the corpus\n",
    "sims = index[query_vec]\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "177.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
